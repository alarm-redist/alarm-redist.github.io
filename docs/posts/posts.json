[
  {
    "path": "posts/2022-07-06-japanese-society-of-quantitative-political-science/",
    "title": "47-Prefectures at the Japanese Society of Quantitative Political Science",
    "description": "We are presenting Friday on malapportionment. ç§ãŸã¡ã¯ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ãŸä¸€ç¥¨ã®æ ¼å·®ã®æ˜¯æ­£ã«ã¤ã„ã¦ã€é‡‘æ›œæ—¥ã«ç™ºè¡¨ã—ã¾ã™ã€‚",
    "author": [
      {
        "name": "Sho Miyazaki",
        "url": {}
      },
      {
        "name": "Kento Yamada",
        "url": {}
      },
      {
        "name": "Rei Yatsuhashi",
        "url": {}
      },
      {
        "name": "Kosuke Imai",
        "url": {}
      }
    ],
    "date": "2022-07-07",
    "categories": [],
    "contents": "\nWe are presenting a poster presentation at the Japanese Society of\nQuantitative Political Science ğŸ‡¯ğŸ‡µ! We show that the well-known\nmalapportionment (ä¸€ç¥¨ã®æ ¼å·®) of the Japanese House of Representatives\ncan be redressed without splitting administrative boundaries.\nALARMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€è¨ˆé‡ãƒ»æ•°ç†æ”¿æ²»ç ”ç©¶ä¼šï¼ˆJSQPSï¼‰ã®å¤å­£é›†ä¼šã«ã¦ãƒã‚¹ã‚¿ãƒ¼ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å‚åŠ è‡´ã—ã¾ã™ã€‚ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è¡†è­°é™¢ã®é¸æŒ™åŒºæ”¹å¤‰ã«å¿œç”¨ã—ã¦ã€å¸‚åŒºç”ºæ‘ã®åˆ†å‰²æ•°ã‚’å¢—ã‚„ã•ãªãã¦ã‚‚ã€ä¸€ç¥¨ã®æ ¼å·®ãŒæ˜¯æ­£ã•ã‚Œã‚‹åŒºå‰²ã‚Šæ¡ˆã‚’ä½œæˆã§ãã‚‹ã“ã¨ã‚’ç™ºè¡¨ã—ã¾ã™ã€‚\nView\nthe poster! Or\nsee the full details of the project.\nãƒã‚¹ã‚¿ãƒ¼ã‚’ã”è¦§ãã ã•ã„ï¼\nè©³ç´°ã¯ã€æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚\n\n\n\n",
    "preview": {},
    "last_modified": "2022-07-07T09:56:22-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-06-20-redist-40/",
    "title": "redist 4.0",
    "description": "A major release with big changes to constraints and diagnostics.",
    "author": [
      {
        "name": "Christopher T. Kenny",
        "url": "https://www.christophertkenny.com/"
      },
      {
        "name": "Cory McCartan",
        "url": "https://www.corymccartan.com"
      }
    ],
    "date": "2022-06-20",
    "categories": [],
    "contents": "\nWe are excited to announce the arrival of redist 4.0.1\non CRAN. This\nupdate focuses on increasing constraint consistency and diagnostic\nusability. The new tools here have been thoroughly tested as part of the\n50-State\nRedistricting Simulations project.\nTo install the new version, run\ninstall.packages('redist').\nNew Features\nA new constraint interface that is more flexible, user friendly, and\nconsistent across algorithms (see redist_constr() and\n?constraints). For the first time, user-defined custom\nconstraints are supported and integrated within all three\nalgorithms.\nNew diagnostic-checking function,\nsummary.redist_plans()\nSummary statistics have been broken out into a new\nredistmetrics package This will speed up compilation time\nand also provides a cleaner, more extensible interface for the\nimplementation of additional metrics.\nParallel computing support for the SMC algorithm, both within and\nacross sampling runs\nReproducible across-run parallelism throughout the package, via\ndoRNG\nMuch faster match_numbers() using the Hungarian\nmethod\nmin_move_parity() calculates how much population needs\nto be moved between districts in order to completely balance a\nredistricting plan.\nSupport for partial SMC simulations, where fewer districts are drawn\nthan the total number. Allows advanced users to manually combine partial\nruns to form complete maps.\nImproved algorithm reporting, including new progress bars and\ncli errors and warnings throughout the package\nUpdate the SMC algorithm to include a missing correction factor for\nthe number of ways to sequentially label districts. This factor should\nnot have an effect on substantive conclusions and summary\nstatistics.\nRemove deprecated functions\nMany bug fixes (see https://github.com/alarm-redist/redist/issues)\nUpdated Features: A Brief\nDemo\nThe first thing youâ€™ll notice upon loading redist is\nthat it also loads redistmetrics.\nredistmetrics used to live within redist but\nhas been separated to keep the package size reasonable and to make the\nindividual compile times shorter.\n\n\nlibrary(tidyverse)\nlibrary(redist)\n\n\n\nWe can pull in some\ndata from the ALARM Project, which combines 2020 Census data with VESTâ€™s\nelection data, retabulated to 2020 voting districts. For this example,\nwe can use data from New Mexico.\n\n\nnm <- geomander::get_alarm('NM')\n\n\n\n\nWe can then make a redist_map for New Mexico.1\n\n\nmap_nm <- redist_map(nm, ndists = 3, pop_tol = 0.005)\n\n\n\nAnd we can begin with a basic run of redist_smc to\nsample 1000 plans using the sampler from Sequential Monte Carlo for\nSampling Balanced and Compact Redistricting Plans by Cory McCartan and Kosuke Imai. Most importantly,\nredist_smc now offers an argument for the number of\nindependent sampling runs. For now, we can break that 1000 plans into 2\nruns of 500.\n\n\nset.seed(2022)\nplans <- redist_smc(map = map_nm, nsims = 500, runs = 2, counties = county)\n\n\n\nThe new messages above are created with cli to more make\nmessage printing cleaner and more consistent.\nTo the output, we can add some basic summary information using\navailable redistmetrics functions, automatically loaded by\nredist.\n\n\nplans <- plans %>% \n    mutate(\n        frac_kept = comp_frac_kept(plans = ., shp = map_nm),\n        dvs_gov_18 = part_dvs(plans = ., shp = map_nm, dvote = gov_18_dem_luj, rvote = gov_18_rep_pea),\n        county_spl = splits_admin(plans = ., shp = map_nm, admin = county)\n    )\n\n\n\nIn order, this adds the Fraction Kept compactness score, the\nDemocratic two-party vote share in the 2018 Governorâ€™s race, and the\nnumber of counties split.\nNow, the plans object has a few new columns:\n\n\nhead(plans)\n\n\nWith plans resampled from weights\nPlans matrix: int [1:1977, 1:1000] 3 3 3 3 3 3 3 3 3 3 ...\n# A tibble: 6 Ã— 7\n  draw  chain district total_pop frac_kept dvs_gov_18 county_spl\n  <fct> <int>    <int>     <dbl>     <dbl>      <dbl>      <int>\n1 1         1        1    706220     0.984      0.474          2\n2 1         1        2    707900     0.984      0.602          2\n3 1         1        3    703402     0.984      0.619          2\n4 2         1        1    707157     0.990      0.508          2\n5 2         1        2    706801     0.990      0.582          2\n6 2         1        3    703564     0.990      0.616          2\n\nDraw, chain, and district identify each plan, where\nchain is new to 4.0 for SMC. It signifies the SMC run,\nsimilar to how redist_mergesplit_parallel indicates the\nchain from merge-split. Despite this, we can use the normal plotting\nfunctions on the redist_plans object. If we load\npatchwork here to get a nice row of ggplots,\nwe see the following:\n\n\nlibrary(patchwork)\nhist(plans, frac_kept) + \n    plot(plans, dvs_gov_18) + \n    hist(plans, county_spl)\n\n\n\n\nThese plots are fairly standard. The exciting thing is that we can\nnow call summary() to get diagnostic information about the\nruns of SMC. We can call this on any redist_plans object\nand it will adjust the output information depending on what algorithm\ngenerated the plans.\n\n\nsummary(plans)\n\n\n\n\nR-hat values for summary statistics:\n frac_kept dvs_gov_18 county_spl \n   1.00259    1.00197    0.99955 \n\n         Eff. samples (%) Acc. rate Log wgt. sd  Max. unique Est. k \nSplit 1       485 (97.0%)      9.9%        0.38   469 ( 94%)     10 \nSplit 2       474 (94.9%)      5.3%        0.48   397 ( 79%)      6 \nResample      411 (82.2%)       NA%        0.48   417 ( 83%)     NA \n\n         Eff. samples (%) Acc. rate Log wgt. sd  Max. unique Est. k \nSplit 1       482 (96.5%)     12.2%        0.41   471 ( 94%)      8 \nSplit 2       476 (95.3%)      6.7%        0.46   405 ( 81%)      5 \nResample      417 (83.4%)       NA%        0.45   419 ( 84%)     NA \n\nEach R-hat value is below 1.05, so we do not get any warnings. At a\nhigh level, this means that both runs of SMC are sampling from regions\ncomparable by these three summary statistics. That isnâ€™t always the case\nthough. If you do get a warning, you should increase the number of\nsimulations or decrease the constraint strengths.\nWe next introduce the new constraint interface. To initialize a\nconstraint, we call redist_constr, which takes a\nredist_map input.\n\n\nconstr <- redist_constr(map = map_nm)\n\n\n\nWe can add any of the many constraints available with\n?constraints. There are many new constraints to people who\nhave only used redist_smc/redist_mergesplit or\nredist_flip before. Now all constraints are available to\nall algorithms. Additionally, we can write pretty much any constraint\nthat we can map to the positive reals, using the new custom\nconstraint.\nFor our custom constraint, we just care that the 100th row of\nmap_nm wonâ€™t be assigned to district 3. We can do the\nfollowing\n\n\nconstr <- constr %>% \n    add_constr_custom(\n        strength = 10,\n        fn = function(plan, distr) {\n            as.numeric(plan[100] != 3)\n        }\n    )\n\n\n\nThis takes an R function fn and a strength value (how\nmuch to multiply the output of fn by). The fn\ninput should always take the form\nfunction(plan, distr) { ... }, where plan will\nbe an integer matrix of precinct-district assignments and\ndistr will be the current district.\nWe can then pass constr to the constraints\nargument in redist_smc().\n\n\nset.seed(2022)\nplans <- redist_smc(map = map_nm, nsims = 500, runs = 2, counties = county, \n                    constraints = constr)\n\n\n\nAgain, we add some summary statistics.\n\n\nplans <- plans %>% \n    mutate(\n        frac_kept = comp_frac_kept(plans = ., shp = map_nm),\n        dvs_gov_18 = part_dvs(plans = ., shp = map_nm, dvote = gov_18_dem_luj, rvote = gov_18_rep_pea),\n        county_spl = splits_admin(plans = ., shp = map_nm, admin = county)\n    )\n\n\n\nThen run the diagnostics:\n\n\nsummary(plans)\n\n\n\n\nR-hat values for summary statistics:\n frac_kept dvs_gov_18 county_spl \n   0.99916    1.00000    1.00845 \n\n         Eff. samples (%) Acc. rate Log wgt. sd  Max. unique Est. k \nSplit 1       484 (96.8%)     10.9%        0.38   475 ( 95%)     10 \nSplit 2       476 (95.1%)      5.7%        0.46   399 ( 80%)      6 \nResample      413 (82.6%)       NA%        0.46   407 ( 81%)     NA \n\n         Eff. samples (%) Acc. rate Log wgt. sd  Max. unique Est. k \nSplit 1       483 (96.6%)     12.8%        0.40   478 ( 96%)      8 \nSplit 2       477 (95.4%)      7.3%        0.45   388 ( 78%)      5 \nResample      419 (83.8%)       NA%        0.45   420 ( 84%)     NA \n\nAnd everything looks good. Despite adding a constraint, the sample\nstill looks fine under these summary statistics.\nFor more information on diagnostics, take a look at McCartan and Imai\n(2022).\n\nFor a very brief intro to\nredist_maps, see the 3.0 release post at https://alarm-redist.github.io/posts/2021-04-02-redist-300/.â†©ï¸\n",
    "preview": "posts/2022-06-20-redist-40/redist-40_files/figure-html5/unnamed-chunk-7-1.png",
    "last_modified": "2022-06-21T13:43:06-07:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2022-04-23-47-prefecture-project/",
    "title": "47-Prefecture Project",
    "description": "Using redistricting simulation methods to better understand redistricting in Japan.",
    "author": [
      {
        "name": "Sho Miyazaki",
        "url": {}
      },
      {
        "name": "Kento Yamada",
        "url": {}
      },
      {
        "name": "Rei Yatsuhashi",
        "url": {}
      },
      {
        "name": "Kosuke Imai",
        "url": {}
      }
    ],
    "date": "2022-04-23",
    "categories": [],
    "contents": "\nThe ALARM Project is pleased to announce the 47-Prefecture Project, whose goal is to generate and analyze redistricting plans for the single-member districts of the House of Representatives of Japan using redistricting simulation algorithms.\n\nLearn more about the project and see the results Â»\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-04-23T11:46:21-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-06-2021-10-06-das-published/",
    "title": "Revised and published: The use of differential privacy for census data and its impact on redistricting",
    "description": "A new postscript analyzes the final version of the U.S. Census Bureau's Disclosure Avoidance System.",
    "author": [
      {
        "name": "Christopher T. Kenny",
        "url": {}
      },
      {
        "name": "Shiro Kuriwaki",
        "url": {}
      },
      {
        "name": "Cory McCartan",
        "url": {}
      },
      {
        "name": "Evan Rosenman",
        "url": {}
      },
      {
        "name": "Tyler Simko",
        "url": {}
      },
      {
        "name": "Kosuke Imai",
        "url": {}
      }
    ],
    "date": "2021-10-07",
    "categories": [],
    "contents": "\nAt the end of May, the ALARM Project released a report examining â€œThe Impact U.S. Census Disclosure Avoidance System on Redistricting and Voting Rights Analysis.â€ The Census Bureau has since updated the system parameters and released 2020 Census Data protected under this Disclosure Avoidance System.\nOur original report has been revised to include an analysis of the new system parameters, and appears today in the journal Science Advances.\nRead the paper: The use of differential privacy for census data and its impact on redistricting: The case of the 2020 U.S. Census\n\n\n\n\n",
    "preview": "https://pbs.twimg.com/media/FA8fplwXsAMVffB?format=jpg&name=large",
    "last_modified": "2021-10-06T11:35:18-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-08-10-census-2020/",
    "title": "2020 Redistricting Data Files",
    "description": "Census and election data joined together for use in redistricting\nand voting rights analysis.",
    "author": [
      {
        "name": "Christopher T. Kenny",
        "url": {}
      },
      {
        "name": "Cory McCartan",
        "url": {}
      }
    ],
    "date": "2021-08-10",
    "categories": [],
    "contents": "\n\nAKALARAZCACOCTDEFLGAHIIAIDILINKSKYLAMAMDMEMIMNMOMSMTNCNDNENHNJNMNVNYOHOKORPARISCSDTNTXUTVAVTWAWIWVWYDCUSA\n\n\nThe ALARM Project is glad to provide precinct-level demographic and election data from the 2020 decennial census and the Voting and Election Science Team which have been tidied and joined together using 2020 precinct boundaries. Where 2020 precinct boundaries are not available, Census block-level data is provided instead, and where no VEST data is available, only demographic information is provided. Code to generate the data from these sources is included; the entire workflow is open-source and reproducible.\nGetting the data\nDownload individual statesâ€™ data below, or download a ZIP of all the data here. Our repository also contains more detailed data, as well as code and instructions for programmatic downloading, adding shapefile geometries, and other use cases.\nPlease make sure to cite the Voting and Election Science Team and the U.S. Census Bureau. Consult the license for information on modifying and sharing the data and/or code.\n2020 state data\n\n\n\n\nÂ \n\nAlabama\n \nVTDs\n\nÂ \n\nÂ \nal_2020_vtd.csv\n\n\n\n\n\nÂ \n\nAlaska\n \nVTDs\n\nÂ \n\nÂ \nak_2020_vtd.csv\n\n\n\n\n\nÂ \n\nArizona\n \nVTDs\n\nÂ \n\nÂ \naz_2020_vtd.csv\n\n\n\n\n\nÂ \n\nArkansas\n \nVTDs\n\nÂ \n\nÂ \nar_2020_vtd.csv\n\n\n\n\n\nÂ \n\nCalifornia\n \nCensus blocks\n\nÂ \n\nÂ \nca_2020_block.csv\n\n\n\n\n\nÂ \n\nColorado\n \nVTDs\n\nÂ \n\nÂ \nco_2020_vtd.csv\n\n\n\n\n\nÂ \n\nConnecticut\n \nVTDs\n\nÂ \n\nÂ \nct_2020_vtd.csv\n\n\n\n\n\nÂ \n\nDelaware\n \nVTDs\n\nÂ \n\nÂ \nde_2020_vtd.csv\n\n\n\n\n\nÂ \n\nDistrict of Columbia\n \nVTDs\n\nÂ \n\nÂ \ndc_2020_vtd.csv\n\n\n\n\n\nÂ \n\nFlorida\n \nVTDs\n\nÂ \n\nÂ \nfl_2020_vtd.csv\n\n\n\n\n\nÂ \n\nGeorgia\n \nVTDs\n\nÂ \n\nÂ \nga_2020_vtd.csv\n\n\n\n\n\nÂ \n\nHawaii\n \nCensus blocks\n\nÂ \n\nÂ \nhi_2020_block.csv\n\n\n\n\n\nÂ \n\nIdaho\n \nVTDs\n\nÂ \n\nÂ \nid_2020_vtd.csv\n\n\n\n\n\nÂ \n\nIllinois\n \nVTDs\n\nÂ \n\nÂ \nil_2020_vtd.csv\n\n\n\n\n\nÂ \n\nIndiana\n \nVTDs\n\nÂ \n\nÂ \nin_2020_vtd.csv\n\n\n\n\n\nÂ \n\nIowa\n \nVTDs\n\nÂ \n\nÂ \nia_2020_vtd.csv\n\n\n\n\n\nÂ \n\nKansas\n \nVTDs\n\nÂ \n\nÂ \nks_2020_vtd.csv\n\n\n\n\n\nÂ \n\nKentucky\n \nVTDs\n\nÂ \n\nÂ \nky_2020_vtd.csv\n\n\n\n\n\nÂ \n\nLouisiana\n \nVTDs\n\nÂ \n\nÂ \nla_2020_vtd.csv\n\n\n\n\n\nÂ \n\nMaine\n \nVTDs\n\nÂ \n\nÂ \nme_2020_vtd.csv\n\n\n\n\n\nÂ \n\nMaryland\n \nVTDs\n\nÂ \n\nÂ \nmd_2020_vtd.csv\n\n\n\n\n\nÂ \n\nMassachusetts\n \nVTDs\n\nÂ \n\nÂ \nma_2020_vtd.csv\n\n\n\n\n\nÂ \n\nMichigan\n \nVTDs\n\nÂ \n\nÂ \nmi_2020_vtd.csv\n\n\n\n\n\nÂ \n\nMinnesota\n \nVTDs\n\nÂ \n\nÂ \nmn_2020_vtd.csv\n\n\n\n\n\nÂ \n\nMississippi\n \nVTDs\n\nÂ \n\nÂ \nms_2020_vtd.csv\n\n\n\n\n\nÂ \n\nMissouri\n \nVTDs\n\nÂ \n\nÂ \nmo_2020_vtd.csv\n\n\n\n\n\nÂ \n\nMontana\n \nVTDs\n\nÂ \n\nÂ \nmt_2020_vtd.csv\n\n\n\n\n\nÂ \n\nNebraska\n \nVTDs\n\nÂ \n\nÂ \nne_2020_vtd.csv\n\n\n\n\n\nÂ \n\nNevada\n \nVTDs\n\nÂ \n\nÂ \nnv_2020_vtd.csv\n\n\n\n\n\nÂ \n\nNew Hampshire\n \nVTDs\n\nÂ \n\nÂ \nnh_2020_vtd.csv\n\n\n\n\n\nÂ \n\nNew Jersey\n \nVTDs\n\nÂ \n\nÂ \nnj_2020_vtd.csv\n\n\n\n\n\nÂ \n\nNew Mexico\n \nVTDs\n\nÂ \n\nÂ \nnm_2020_vtd.csv\n\n\n\n\n\nÂ \n\nNew York\n \nVTDs\n\nÂ \n\nÂ \nny_2020_vtd.csv\n\n\n\n\n\nÂ \n\nNorth Carolina\n \nVTDs\n\nÂ \n\nÂ \nnc_2020_vtd.csv\n\n\n\n\n\nÂ \n\nNorth Dakota\n \nVTDs\n\nÂ \n\nÂ \nnd_2020_vtd.csv\n\n\n\n\n\nÂ \n\nOhio\n \nVTDs\n\nÂ \n\nÂ \noh_2020_vtd.csv\n\n\n\n\n\nÂ \n\nOklahoma\n \nVTDs\n\nÂ \n\nÂ \nok_2020_vtd.csv\n\n\n\n\n\nÂ \n\nOregon\n \nCensus blocks\n\nÂ \n\nÂ \nor_2020_block.csv\n\n\n\n\n\nÂ \n\nPennsylvania\n \nVTDs\n\nÂ \n\nÂ \npa_2020_vtd.csv\n\n\n\n\n\nÂ \n\nRhode Island\n \nVTDs\n\nÂ \n\nÂ \nri_2020_vtd.csv\n\n\n\n\n\nÂ \n\nSouth Carolina\n \nVTDs\n\nÂ \n\nÂ \nsc_2020_vtd.csv\n\n\n\n\n\nÂ \n\nSouth Dakota\n \nVTDs\n\nÂ \n\nÂ \nsd_2020_vtd.csv\n\n\n\n\n\nÂ \n\nTennessee\n \nVTDs\n\nÂ \n\nÂ \ntn_2020_vtd.csv\n\n\n\n\n\nÂ \n\nTexas\n \nVTDs\n\nÂ \n\nÂ \ntx_2020_vtd.csv\n\n\n\n\n\nÂ \n\nUtah\n \nVTDs\n\nÂ \n\nÂ \nut_2020_vtd.csv\n\n\n\n\n\nÂ \n\nVermont\n \nVTDs\n\nÂ \n\nÂ \nvt_2020_vtd.csv\n\n\n\n\n\nÂ \n\nVirginia\n \nVTDs\n\nÂ \n\nÂ \nva_2020_vtd.csv\n\n\n\n\n\nÂ \n\nWashington\n \nVTDs\n\nÂ \n\nÂ \nwa_2020_vtd.csv\n\n\n\n\n\nÂ \n\nWest Virginia\n \nVTDs\n\nÂ \n\nÂ \nwv_2020_vtd.csv\n\n\n\n\n\nÂ \n\nWisconsin\n \nVTDs\n\nÂ \n\nÂ \nwi_2020_vtd.csv\n\n\n\n\n\nÂ \n\nWyoming\n \nVTDs\n\nÂ \n\nÂ \nwy_2020_vtd.csv\n\n\n\n\nUsing the data\nData Format\nEach data table contains several identification columns, a set of census-derived demographic columns, and a set of VEST-derived election columns.\nGEOID20 is the unique identifier for a precinct or Census block. The state and county of the precinct or block are also provided.\nCensus variables are prefixed with pop_ or vap_, depending on whether they are for the entire population or the voting-age population. Suffixes refer to racial and ethnic categories, as follows:\n_hisp: Hispanic or Latino (of any race)\n_white: White alone, not Hispanic or Latino\n_black: Black or African American alone, not Hispanic or Latino\n_aian: American Indian and Alaska Native alone, not Hispanic or Latino\n_asian: Asian alone, not Hispanic or Latino\n_nhpi: Native Hawaiian and Other Pacific Islander alone, not Hispanic or Latino\n_other: Some Other Race alone, not Hispanic or Latino\n_two: Population of two or more races, not Hispanic or Latino\n\nElection variables consist of average vote counts for Democratic and Republican candidates. The adv_## and arv_## columns report the average vote count in the ## election, across all statewide races contested by both parties. The ndv and nrv columns further average the vote counts across all available election years. For specific statewide races, you may download the files in vest-2020/ and join them to the data using the GEOID20 column.\nMore Tools\nFor redistricting and voting rights analysis, we recommend the redist package.\nFor pre-processing and tidying data for redistricting analysis, we recommend the geomander package.\nFor more custom tabulations of the 2020 census data, we recommend the PL94171 package.\nFor general-purpose census data processing, we recommend the censable package.\nFor alternate data unaffected by Census differential privacy, you may want to consider FCC block-level estimates, available using the blockpop package.\nTechnical notes\nTo produce election data using 2020 precinct boundaries, election results were projected down to the 2010 block level using voting-age population as weights. Results for 2020 blocks were then estimated using 2010 blocks and the land-use-based crosswalk files from VEST. Finally, 2020 blocks were aggregated to 2020 precincts using the Censusâ€™ 2020 block assignment files.\n\n\n\n",
    "preview": "https://alarm-redist.github.io/posts/2021-08-10-census-2020/graphic.png",
    "last_modified": "2021-11-12T10:49:04-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-05-revised-das-impact/",
    "title": "Revised: Impact of the Census Disclosure Avoidance System",
    "description": "We are releasing an updated version of our analysis of the U.S. Census'\nprivacy protection system and its impacts on the redistricting process.",
    "author": [
      {
        "name": "Christopher T. Kenny",
        "url": {}
      },
      {
        "name": "Shiro Kuriwaki",
        "url": {}
      },
      {
        "name": "Cory McCartan",
        "url": {}
      },
      {
        "name": "Evan Rosenman",
        "url": {}
      },
      {
        "name": "Tyler Simko",
        "url": {}
      },
      {
        "name": "Kosuke Imai",
        "url": {}
      }
    ],
    "date": "2021-07-05",
    "categories": [],
    "contents": "\nLast month, the ALARM Project released a report examining â€œThe Impact U.S. Census Disclosure Avoidance System on Redistricting and Voting Rights Analysis.â€ We thank everyone who provided us with feedback on this first version, which was written as a comment on the April 28, 2021 Demonstration Data. The Census Bureau has since updated the system parameters, and as such, we are releasing an updated version.\nRevised report: The Impact of the U.S. Census Disclosure Avoidance System on Redistricting and Voting Rights Analysis\nNotably, we expand our study of bias related to racial heterogeneity to include four new states of interest: Alabama, Delaware, Utah, and Washington. We also expand our studies of partisan and racial effects in redistricting to include more cases and provide additional information on the ranges of possible outcomes. These changes come alongside a restructuring of the paper and several smaller edits to recognize additional work focused on the new DAS methodologies used this year by the Census Bureau.With this version, we are also releasing replication data and code, available on the Harvard Dataverse.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-07-05T18:30:18-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-09-dsep-decision-response/",
    "title": "Reaction to the Census Bureau's Updated Parameters",
    "description": "The Data Stewardship Executive Policy Committee announces a higher privacy \nloss budget and other changes to the Disclosure Avoidance System.",
    "author": [
      {
        "name": "Christopher T. Kenny",
        "url": {}
      },
      {
        "name": "Shiro Kuriwaki",
        "url": {}
      },
      {
        "name": "Cory McCartan",
        "url": {}
      },
      {
        "name": "Evan Rosenman",
        "url": {}
      },
      {
        "name": "Tyler Simko",
        "url": {}
      },
      {
        "name": "Kosuke Imai",
        "url": {}
      }
    ],
    "date": "2021-06-09",
    "categories": [],
    "contents": "\nOn June 9, The Census Bureau released information on their final parameters for the 2020 Census data release. We are grateful that they have incorporated some of the recommendations from our report to help build a better data product for redistricting.\nThe Bureau has made several welcome changes. They state that they have updated the post-processing component of the Disclosure Avoidance System (DAS) to address the undercounting bias in racially and ethnically diverse areas, which we reported in our analysis. As we recommended, the Bureau has also increased the privacy-loss budget, allocating the increase towards more accurate population and racial counts on geographies at the block group level and higher. We are hopeful that this targeted increase will help attenuate the DAS- induced population change at the voting district and precinct level.\nSome unresolved issues remain, however. The Bureau indicates that a new demonstration data product will not be released until September. Yet they plan to first release 2020 census redistricting data, which we expect states and localities to begin using immediately, by August 16, 2021.1 Given the timing, it is unclear how the evaluation of the new demonstration data will affect the upcoming redistricting process and related litigation.Â  The Bureau also states that there will be no direct increases in accuracy for block-level data, in order to protect privacy.Â  As this is a key aspect of ensuring the equality of vote and protecting the principle of One Person, One Vote, map drawers and analysts may have to adjust their interpretation of this long-standing principle.\nThe Bureau also announced that they plan to release the final version of the DAS code base.Â  This is an important step for transparency. However, the code alone does not allow analysts to evaluate the impacts of DAS on redistricting and properly account for the additional uncertainty due to the injected noise. We recommend the Bureau also release differentially private noisy population counts that have not been subject to the post-processing steps, as well as parameter values used for noise generation. Although scholarly communities have not fully resolved the issue of incorporating additional noise into redistricting simulation analysis, the availability of such information should facilitate future methodological development. In particular, it is of interest to examine whether or not the additional noise makes it more difficult to detect partisan and racial gerrymandering.\n\nCaliper, who makes the software Maptitude for Redistricting, has announced they will process the legacy format data, and two ALARM Project members have created an R package to process legacy data as well. These types of resources should allow people to immediately begin drawing maps.â†©ï¸\n",
    "preview": "posts/2021-06-09-dsep-decision-response/census_slide.jpg",
    "last_modified": "2021-06-09T17:36:09-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-02-das-evaluation-faq/",
    "title": "FAQ: Impact of the Census Disclosure Avoidance System",
    "description": "Answers to common questions about our recently-released report \nevaluating the Census' Disclosure Avoidance System.",
    "author": [
      {
        "name": "Christopher T. Kenny",
        "url": {}
      },
      {
        "name": "Shiro Kuriwaki",
        "url": {}
      },
      {
        "name": "Cory McCartan",
        "url": {}
      },
      {
        "name": "Evan Rosenman",
        "url": {}
      },
      {
        "name": "Tyler Simko",
        "url": {}
      },
      {
        "name": "Kosuke Imai",
        "url": {}
      }
    ],
    "date": "2021-06-02",
    "categories": [],
    "contents": "\n\nContents\nAre you advocating for the use of swapping methods over differential privacy as a method of privacy protection?\nDoes the DAS noise â€œcancel outâ€ at larger geographic scales?\nWill the noisy data make it harder to create partisan gerrymanders?\nWhy is using a simulation-based method useful to assess DAS? What are the downsides?\nWhy do you use strict thresholds to define equal district population parity, thereby labelling more plans invalid?\nWhy do you use a strict threshold of 50% to define the majority-minority districts (MMDs)?\nWhy does your analysis not adjust for the differential privacy (DP) mechanism, to properly measure uncertainty?\nDo your findings about the prediction of individual race contradict the property of differential privacy?\nWhat are the differences between your analysis and MGGGâ€™s analysis, both of which are based on simulation methods?\nWhy do you rely on Census data as the â€˜ground-truthâ€™? Doesnâ€™t the Census itself already have enumeration error?\n\nWe have received a large number of questions and suggestions since releasing the first version of our report on Friday, May 28th. After meeting the Census Bureauâ€™s one month deadline to produce comments on DAS-protected data, we are continuing to undertake additional analyses of the impacts of DAS on the redistricting process and analyses. We are working towards releasing the revised report soon. In the meantime, we provide our current answers to the questions frequently asked by others below.\nAre you advocating for the use of swapping methods over differential privacy as a method of privacy protection?\nNo.Â We have not studied the impact of swapping on redistricting. It is well known that differential privacy (DP) is theoretically superior to swapping in terms of privacy protection. The key policy question is how much privacy protection we would want at the expense of accurate census measurements. We argue that when changing an important public policy, such as whether additional noise should be added to the census, one needs to carefully determine the impacts of such policy change. We do not argue against DP and believe additional privacy protections to be a worthy consideration for some of the Census variables and products. However, we find that the current implementation of DAS can lead to substantively important changes in redistricting outcomes while also not meaningfully protecting privacy (as demonstrated by the fact that the prediction of individual race remains accurate even with the DAS data). We believe that more studies are needed to determine whether to inject noise and if so how exactly noise should be added. We hope that our study, along with many others, is the first step in answering this important question, by showing the potential consequences of the current DAS on certain redistricting outcomes.\nDoes the DAS noise â€œcancel outâ€ at larger geographic scales?\nTheoretically yes, but with a caveat. The DAS is designed to have less noise at larger geographic scales, especially for levels of geography in the Census hierarchy, known as â€œon-spineâ€ geographies (blocks, block groups, tracts, and counties). But geographies like Census places and voting precincts (VTDs) are â€œoff-spineâ€. The design of the DAS may induce noise that does not cancel out in off-spine geographies.\nOur analysis finds that not only is there more noise for VTDs, but also that there remains a particular form of previously undiscussed bias â€” perhaps an unintentional side-effect of the DAS post-processing procedure needing to satisfy accuracy constraints in on-spine geographies. We find that the DAS data systematically undercounts racially and politically diverse VTDs in comparison to more homogeneous VTDs. How these discrepancies add up into legislative districts clearly depends on the spatial adjacency of diverse and homogenous VTDs. But in some cases the bias does not cancel out. In Pennsylvania, the average Congressional district changes by only 400 or so people. But the majority-Black 3rd Congressional District gains around 2,000 people under the DAS-protected data, while the more diverse 2nd Congressional District, a Black-Hispanic coalition district, loses around 2,000 people.\nWill the noisy data make it harder to create partisan gerrymanders?\nIn general, no. Partisan gerrymanders can be made with election data and voter files, both of which are not part of the Census and so will not contain any DAS-based error. Other residential and political data sources (both public and private) exist as well, which could be used to draw skewed districts. However, for analysts who must use noisy Census data to identify and analyze a potential gerrymander, the noise and the partisan biases discussed above may make it more difficult to do so.\nWhy is using a simulation-based method useful to assess DAS? What are the downsides?\nWithout the use of simulation, we are restricted to verifying changes in enacted redistricting plans. Analyzing enacted plans under a particular DAS dataset may not allow us to understand how DAS affects other similar plans. By using simulation methods, we are able to draw new maps with the DAS data under realistic constraints while taking into account the geography and spatial distributions of populations.Â  A downside of simulation is that the results will depend on the types of redistricting maps the algorithms are designed to generate.Â  More studies are needed to better understand how DAS affects different types of redistricting maps.\nWhy do you use strict thresholds to define equal district population parity, thereby labelling more plans invalid?\nThe use of strict thresholds is informed by a long series of Supreme Court decisions which establish and define the â€œone person, one voteâ€ principle.Â  Current practice for redistricting congressional districts is to minimize the population difference across as much as possible.Â  As summarized by the National Conference of State Legislatures, in many states, this means getting district populations to be within a single person of one another, based on the Census counts.Â  If only noisy data is available, drawing districts to minimize the population difference becomes at best ambiguous.Â  Our analysis demonstrates the current statutory and judicial standards may not be applicable to the DAS-protected data.Â  On this point, our findings about the magnitude of population changes agree with many other analyses of the DAS and the April 28 Demonstration Data.Â  If the DAS data will be used for redistricting, the key question will be if and how to change the interpretation of â€œone person, one voteâ€ principle and how such a change will affect redistricting in practice.\nWhy do you use a strict threshold of 50% to define the majority-minority districts (MMDs)?\nWe use a 50% threshold for majority minority districts to remain in line with the jurisprudence following Thornburg v. Gingles (1986). Specifically, Bartlett v. Strickland (2009) held that a minority must â€œconstitute a numerical majority of the voting-age population in an area before Â§2 requires the creation of a legislative district to prevent dilution of that groupâ€™s votes.â€ When simulating districts, the number of districts which satisfy this specific numerical constraint is thus important. There are other ways to think about minority voting in elections, such as â€œopportunity districtsâ€, â€œcoalitional districtsâ€, â€œcrossover districtsâ€, and â€œinfluence districts.â€ These have less concrete definitions and rely on electoral data, rather than just Census data.Â  Certainly, strict majorities are not the only relevant measure of minority voting power, and its coarseness makes it sensitive to change introduced by the DAS.Â  We find that the practice of using strict thresholds for majority minority districts may lead to biased results especially for small districts such as state legislative districts and school boards.\nWhy does your analysis not adjust for the differential privacy (DP) mechanism, to properly measure uncertainty?\nOur analysis examines the consequences of a map drawer taking DAS-protected data as-is. Ideally, analysts can also adjust for the DP mechanism into that data.Â  However, the Bureauâ€™s deterministic and asymmetric post-processing procedure cannot be easily incorporated into standard redistricting analyses, preventing analysts from quantifying the added uncertainty exactly.Â  We recommend that the Bureau release the DP data without post-processing, allowing analysts to adjust redistricting plans with this added uncertainty.Â \nDo your findings about the prediction of individual race contradict the property of differential privacy?\nTechnically, no. Differential privacy guarantees that the inference based on a database does not depend on whether or not a particular individual is included in the data.Â  However, one might argue that for the PL94-171 data, the only sensitive information to be protected is race.Â  Our prediction methodology combines the census block level racial composition with the publicly available addresses and names of registered voters.Â  We found that our overall prediction performance does not degrade even if we use the noise-added census block data. And, yet, in our reanalysis of a recent court case where this prediction methodology was prominently used, the prediction appears to be substantively different.Â  We are in the process of studying when and how these differences arise.Â  In general, when deciding what privacy to protect at the cost of inaccurate measurements, it is important to consider the consequences of privacy disclosure.Â  Our finding suggests that the addition of noise to the census data does not necessarily improve the privacy protection in terms of individualsâ€™ race.\nWhat are the differences between your analysis and MGGGâ€™s analysis, both of which are based on simulation methods?\nThe MGGG Redistricting Lab has also released a study on using DAS data for redistricting purposes, which we believe is well done. In many ways, our results agree with those of the MGGG team. Like the MGGG study, we also find district-level population errors on the scale of hundreds or thousands of people depending on the size of the district (including Section 5 in our analysis and Figure 4 in the MGGG analysis). The core differences in these results come from interpretation. We find similarly sized errors and consider them to be major differences given that districts in many scenarios are drawn to be as exact as possible, down to individual people in many states. For example, Karcher v. Daggett (1983) found that even minute differences in population parity across congressional districts must be justified, even when smaller than the expected error in the decennial census. The MGGG team interprets their results in light of existing noise in current Census data, and say that â€œthe practice of one-person population deviation across districts was never reasonably justified by the accuracy of Census data nor required by law.â€Â  This implies that if DAS data are to be adopted, courts must decide how to change the interpretation of â€œone person, one voteâ€ principle.\nOur analysis differs from the MGGG paper in several ways as well, and more studies are needed in order to better understand the impact of DAS on redistricting analysis and evaluation. First, our analysis relies on different data. We use the April 28th Demonstration Data, which the Census says will â€œclosely approximateâ€ the final data product, and span several states. The MGGG team uses the publicly available implementation of the 2018 TopDown algorithm with a reconstruction experiment to study Texas, mostly Dallas County, so our studies do not overlap in geographic areas.\nSecond, our analysis is focused on voting precincts (VTDs), which are the building blocks used in constructing redistricting plans in the vast majority of states.Â  Election results are also reported at this level or the state equivalent. In contrast, the MGGG analysis built districts out of Census blocks, block groups, and tracts.Â  These geographies are called â€œon-spineâ€ by the Census bureau, since they nest within each other. Crucially, the DAS is designed to minimize error for these on-spine geographies, but not for off-spine geographies like VTDs. This may explain why our analysis finds more noise in the VTD population and racial counts than the MGGGâ€™s analysis.\nWhy do you rely on Census data as the â€˜ground-truthâ€™? Doesnâ€™t the Census itself already have enumeration error?\nCensus data, as acknowledged by the Bureau, has errors as well, including undercounts of some minority groups. Despite these inaccuracies, we rely on Census data for our simulations because governments and courts generally consider Census data as â€œground-truthâ€ for the purposes of drawing districts (e.g., Karcher v. Daggett 1983). The purpose of our analysis is to investigate how relying on DAS data, rather than on Census data as has generally been done in the past, may lead to different results in some cases. In an ideal world, districts drawn using DAS data would be substantively identical to those drawn with Census data. However, we find cases where districts differ by hundreds or thousands of people depending on whether one relies on the Census or DAS data. Additionally, we believe that more research is necessary to determine whether or not existing enumeration errors will cancel out the error induced by DAS, particularly for â€œoff-spineâ€ but substantively important geographies like VTDs.\nAs noted by other researchers, enumeration error is also substantively different from the random error injected as part of the DAS.Â  At small scales like Census blocks, DAS-injected noise is likely on a larger scale than enumeration errorâ€”some Census places have seen their population doubled or halved under the DAS, while such a result is unlikely with enumeration methods. As others have pointed out, this has the effect of adding a large random element on top of the more systematic enumeration errors, which tend to overcount or undercount larger areas or entire minority groups.Â  DAS does not remove or address these systematic errors; it only adds more error on top of them.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-02T18:58:53-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-28-census-das/",
    "title": "Impact of the Census Disclosure Avoidance System on Redistricting",
    "description": "In attempting to protect the privacy of 2020 Census respondents, the Census \nBureau has made its data unsuitable for redistricting purposes.",
    "author": [
      {
        "name": "Christopher T. Kenny",
        "url": {}
      },
      {
        "name": "Shiro Kuriwaki",
        "url": {}
      },
      {
        "name": "Cory McCartan",
        "url": {}
      },
      {
        "name": "Evan Rosenman",
        "url": {}
      },
      {
        "name": "Tyler Simko",
        "url": {}
      },
      {
        "name": "Kosuke Imai",
        "url": {}
      }
    ],
    "date": "2021-05-28",
    "categories": [],
    "contents": "\nThe U.S. Census Bureau plans to protect the privacy of 2020 Census respondents through its Disclosure Avoidance System (DAS), which attempts to achieve differential privacy guarantees by adding noise to the Census data. The Bureau has asked for feedback on the adequacy of DAS-protected data for real-world purposes. The ALARM project has conducted an extensive analysis into how the DAS-protected data affects redistricting and voting rights analyses, and has submitted these findings to the Census Bureau.\nRead the report: The Impact of the U.S. Census Disclosure Avoidance System on Redistricting and Voting Rights Analysis\nAlso see: Answers to Frequently Asked Questions Added on June 2, 2021.\nA figure from the report, indicating partisan biases in the DAS-protected data.By applying redistricting simulation and analysis methods to DAS-protected 2010 Census data, we find that the protected data are not of sufficient quality for redistricting purposes. Compared to the original Census 2010 data, we find that the DAS-protected data:\nPrevent map drawers from creating districts that satisfy the One Person, One Vote principle, according to current statutory and judicial standards. Actual deviations from equal population will generally be several times larger than as reported under the DAS data. The magnitude of this problem increases for smaller districts such as state legislative districts and school boards.\nTransfer population from low-turnout, mixed-party areas to high-turnout, single-party areas. This differential bias leads to different district boundaries, which in turn implies significant and unpredictable differences in election results. The discrepancy also degrades the ability of analysts to reliably identify partisan gerrymanders.\nTransfer population from racially mixed areas to racially segregated areas. This bias effectively means racially heterogeneous areas are under-counted. The degree of racial segregation can therefore be over-estimated, which can lead to a change in the number of majority-minority districts. It also creates significant precinct-level variability, which adds substantial unpredictability to whether or not a minority voter is included in a majority-minority district.\nAlter individual-level race predictions constructed from voter names and addresses. This leads to fewer estimated minority voters and majority-minority districts in a re-analysis of a recent Voting Rights Act case, NAACP v. East Ramapo School District. At a statewide level, however, the DAS data does not curb the ability of algorithms to identify the race of voters from names and addresses. Therefore, this casts doubt on the universal privacy protection guarantee of DAS data.\nOur primary recommendation is to release Census P.L. 94-171 data without using the Disclosure Avoidance System, and instead rely on a swapping method similar to that applied to the 2010 Census data in order to protect respondent privacy.\nIf the Census Bureau decides to apply the current DAS to Census PL. 94-171 Data, we recommend increasing the privacy loss budget and allocating the increase to improving redistricting outcomes. In particular, preserving the accuracy of populations at the voting tabulation district level would be critical. The Bureau must avoid injecting noise that systematically undercounts certain racial and partisan groups in the privacy-protected data. Additional recommendations are given in the paper.\n\n\n\n",
    "preview": "posts/2021-05-28-census-das/ex_plot.png",
    "last_modified": "2021-06-05T10:07:29-07:00",
    "input_file": {},
    "preview_width": 1500,
    "preview_height": 1200
  },
  {
    "path": "posts/2021-04-02-redist-300/",
    "title": "redist 3.0",
    "description": "A major release brings new algorithms, new workflows, and significant \nusability improvements.",
    "author": [
      {
        "name": "Cory McCartan",
        "url": "https://corymccartan.github.io/"
      },
      {
        "name": "Christopher Kenny",
        "url": "https://www.christophertkenny.com/"
      }
    ],
    "date": "2021-04-07",
    "categories": [],
    "contents": "\nThe ALARM Project is excited to announce the release of redist 3.0 on CRAN. This release brings with it new algorithms and major new workflow improvements, making redistricting analysis broadly accessible to data scientists everywhere.\n\nInstall the new version with install.packages(\"redist\").\nNew Features\nThis release includes far too many changes to list comprehensively. Key improvements and new features include:\nNew tidy interface, including new redist_map and redist_plans objects\nMerge-split MCMC now available in redist_mergesplit()\nShort burst MCMC optimization now available in redist_shortburst() along with scoring functions\nImproved Flip MCMC interface and performance improvements\nNew support for larger simulation size limits\nFunctions to freeze parts of a map and extract district cores\nNew VRA constraint\nMany new plotting functions\nConsistent function and argument names\nNew partisanship and compactnes metrics\nPerformance improvements to compactness calculations\nPlan comparison and classification in compare_plans() and classify_plans()\nNew iowa dataset and cleaned-up package data\nTo begin exploring the new features, check out the new Get Started vignette.\nWorkflow Example: North Carolina\nTo demonstrate the new redist workflow, weâ€™ll run through a basic analysis of the 2017 congressional districts of the state of North Carolina, which were struck down as an unconstitutional partisan gerrymander in 2019.\nNew workflow\n\n\nlibrary(tidyverse)\nlibrary(redist)\n\ndownload.file(\"https://github.com/alarm-redist/redist-data/raw/main/data/nc.rds\",\n              data_path <- tempfile())\nnc_shp <- readRDS(data_path) %>%\n    select(vtd:vap, el14g_uss_r:geometry)\n\n\n\nUnder the new workflow, a redistricting analysis begins with a redist_map object, which defines the basic parameters of the redistricting problem. The redist_map() constructor builds the precinct adjacency graph which is required for redistricting simulation, and stores relevant metadata, such as the desired population parity tolerance and a reference to the existing districts. It also comes with helpful plotting functions.\n\n\nnc = redist_map(nc_shp, existing_plan=cd_17, pop_tol=0.01)\nprint(nc)\n\n\nA redist_map object with 2692 units and 15 fields\nTo be partitioned into 13 districts with population between 733,499 - 1.0% and 733,499 + 1.0%\nWith geometry:\n    bbox:           xmin: 406820 ymin: 2696.2 xmax: 3070200 ymax: 1043600\n    projected CRS:  NAD83(HARN) / North Carolina (ftUS)\n# A tibble: 2,692 x 15\n   vtd       county   pop   vap el14g_uss_r el14g_uss_d el14g_uss_l\n * <chr>     <chr>  <int> <int>       <int>       <int>       <int>\n 1 3700106W  37001   1973  1505         181         182          17\n 2 3700112E  37001   3391  2503         180         271          21\n 3 3700112W  37001   2744  2156         457         481          42\n 4 3700106N  37001   4468  3167         231         466          31\n 5 37001126  37001   2038  1713         670         416          38\n 6 37001124  37001   2455  1948         491         391          33\n 7 370011210 37001   2802  2127         358         309          31\n 8 3700103N  37001   5712  4955        1063         853          53\n 9 3700102   37001   4491  3483        1246         313          62\n10 3700106E  37001   3113  2371         423         432          42\n# â€¦ with 2,682 more rows, and 8 more variables: el14g_uss_wi <int>,\n#   el14g_uss_tot <int>, cd_13 <int>, cd_17 <int>, aland10 <dbl>,\n#   awater10 <dbl>, geometry <MULTIPOLYGON [US_survey_foot]>,\n#   adj <list>\n\nplot(nc, el14g_uss_d/(el14g_uss_d+el14g_uss_r)) +\n    scale_fill_gradient2(midpoint=0.5)\n\n\n\n\nOnce weâ€™ve created a redist_map object, we can simulate redistricting plans.\n\n\nplans = redist_smc(nc, 1000, counties=county, silent=TRUE) # 1000 plans\nprint(plans)\n\n\n1000 sampled plans and 1 reference plan with 13 districts from a 2692-unit map,\n  drawn using Sequential Monte Carlo\nWith plans resampled from weights\nPlans matrix: num [1:2692, 1:1001] 6 6 6 6 6 6 6 6 6 6 ...\n# A tibble: 13,013 x 3\n   draw  district total_pop\n   <fct>    <int>     <dbl>\n 1 cd_17        1    733323\n 2 cd_17        2    734740\n 3 cd_17        3    732627\n 4 cd_17        4    733218\n 5 cd_17        5    733879\n 6 cd_17        6    733554\n 7 cd_17        7    734750\n 8 cd_17        8    734777\n 9 cd_17        9    731507\n10 cd_17       10    736057\n# â€¦ with 13,003 more rows\n\nThe plans variable is a redist_plans objectâ€”a special container designed to make handling sets of redistricting plans painless. As the output above shows, plans contains the 1,000 samppled plans, plus the 2017 congressional districts. We can plot a few of these plans.\n\n\nredist.plot.plans(plans, draws=c(\"cd_17\", \"1\", \"2\", \"3\"), geom=nc)\n\n\n\n\nA redist_plans object makes it easy to compute plan and district summary statistics.\n\n\nplans = plans %>%\n    mutate(comp = distr_compactness(nc),\n           dem_share = group_frac(nc, el14g_uss_d, el14g_uss_d + el14g_uss_r))\nprint(plans)\n\n\n1000 sampled plans and 1 reference plan with 13 districts from a 2692-unit map,\n  drawn using Sequential Monte Carlo\nWith plans resampled from weights\nPlans matrix: num [1:2692, 1:1001] 6 6 6 6 6 6 6 6 6 6 ...\n# A tibble: 13,013 x 5\n   draw  district total_pop  comp dem_share\n   <fct>    <int>     <dbl> <dbl>     <dbl>\n 1 cd_17        1    733323 0.803     0.687\n 2 cd_17        2    734740 0.803     0.443\n 3 cd_17        3    732627 0.803     0.407\n 4 cd_17        4    733218 0.803     0.674\n 5 cd_17        5    733879 0.803     0.425\n 6 cd_17        6    733554 0.803     0.441\n 7 cd_17        7    734750 0.803     0.446\n 8 cd_17        8    734777 0.803     0.439\n 9 cd_17        9    731507 0.803     0.440\n10 cd_17       10    736057 0.803     0.419\n# â€¦ with 13,003 more rows\n\nFrom there, we can quickly generate informative plots. First we check the compactness of the generated plans, and see that they are significantly more compact than the adopted 2017 plan.\n\n\nhist(plans, comp) +\n    labs(x=\"Compactness score (higher is more compact)\")\n\n\n\n\nNext, we look at the partisan implications of the 2017 plan. We plot the two-party Democratic vote share in each district, with districts sorted by this quantity. Each dot on the plot below is a district from one simulated plan, and the red lines show the values for the 2017 plan.\n\n\nredist.plot.distr_qtys(plans, dem_share, size=0.1)\n\n\n\n\nWe see immediately that the 2017 plan packs Democratic voters into the three most Democratic districts, and cracks them in the remaining 10 districts, leading to a durable 10â€“3 Republican-Democratic seat split (in an election which Democrats captured 49% of the statewide two-party vote). A clear partisan gerrymander.\nStudying districts 1, 2, and 4\nIf we want to study a specific set of districts, we can quickly filter() to the relevant map area and re-run the analysis. The redist_map() object will handle all appropriate adjustments to the adjacency graph, number of districts, and population tolerance (as is visible below).\n\n\nnc_sub = filter(nc, cd_17 %in% c(1, 2, 4))\nprint(nc_sub)\n\n\nA redist_map object with 571 units and 15 fields\nTo be partitioned into 3 districts with population between 733,760 - 1.0353% and 733,760 + 0.96399%\nWith geometry:\n    bbox:           xmin: 1921600 ymin: 524880 xmax: 2784100 ymax: 1028200\n    projected CRS:  NAD83(HARN) / North Carolina (ftUS)\n# A tibble: 571 x 15\n   vtd     county   pop   vap el14g_uss_r el14g_uss_d el14g_uss_l\n * <chr>   <chr>  <int> <int>       <int>       <int>       <int>\n 1 37015C2 37015   2182  1707         174         503          13\n 2 37015M1 37015   1103   849         172         167           5\n 3 37015C1 37015   1229   986         229         184          11\n 4 37015MH 37015    992   811         146         254          12\n 5 37015W2 37015    966   764         286          47          20\n 6 37015W1 37015   7005  5703         596        1190          44\n 7 37015M2 37015   1290   983          99         239          16\n 8 37015SN 37015   1410  1025          63         327          11\n 9 37015WH 37015   1554  1274         292         262          12\n10 37015WD 37015   1409  1050          35         319           5\n# â€¦ with 561 more rows, and 8 more variables: el14g_uss_wi <int>,\n#   el14g_uss_tot <int>, cd_13 <int>, cd_17 <int>, aland10 <dbl>,\n#   awater10 <dbl>, geometry <MULTIPOLYGON [US_survey_foot]>,\n#   adj <list>\n\nplot(nc_sub)\n\n\n\n\nOn this subset, too, the adopted 2017 plan is a significant outlier.\n\n\nplans_sub = redist_smc(nc_sub, 1000, counties=county, silent=T) %>%\n    mutate(dem_share = group_frac(nc_sub, el14g_uss_d, el14g_uss_d + el14g_uss_r))\nredist.plot.distr_qtys(plans_sub, dem_share, size=0.3)\n\n\n\n\nOld workflow\nIn comparison, the old workflow required significantly more steps and manual processing.\n\n\nlibrary(tidyverse)\nlibrary(redist)\n\ndownload.file(\"https://github.com/alarm-redist/redist-data/raw/main/data/nc.rds\",\n              data_path <- tempfile())\nnc_shp <- readRDS(data_path) %>%\n    select(vtd:vap, el14g_uss_r:geometry)\n\n\n\nOnce weâ€™ve downloaded the data, we can start by building the adjacency graph.\n\n\nadj <- redist.adjacency(nc_shp)\n\n\n\nTime to first simulation was never really the issue, however each simulation required many inputs. redist_map objects keep track of the adj, total_pop, ndists, and pop_tol arguments, but in the older version, you had to specify each of these for every simulation. One of the quirky aspects of the older version was that counties needed to be a vector with values 1:n_counties, meaning that you had to manually transform it to use it and that only worked if the counties were contiguous.\n\n\nsims <- redist.smc(adj = adj, total_pop = nc_shp$pop, ndists = 13, \n                   pop_tol = 0.01, \n                   counties = match(nc_shp$county, unique(nc_shp$county)), \n                   nsims = 1000, silent = TRUE)\n\n\n\nOnce you finished simulating, setting up plots was always a hassle, as you needed to plot both the distribution of simulations and then compute the same metric separately for the reference plan, in this case thatâ€™s the 2017 congressional districts.\n\n\nmetrics <- redist.metrics(plans = sims$plans, measure = 'DVS',\n                          rvote = nc_shp$el14g_uss_r, nc_shp$el14g_uss_d)\n\nsorted <- metrics %>% \n  group_by(draw) %>% \n  arrange(DVS,.by_group = TRUE) %>% \n  mutate(district = 1:13) %>% \n  ungroup()\n\nreference_metrics <- redist.metrics(plans = nc_shp$cd_17, \n                                    measure = 'DVS', \n                                    rvote = nc_shp$el14g_uss_r, \n                                    dvote = nc_shp$el14g_uss_d)\n\nsorted_reference <- reference_metrics %>% \n    arrange(DVS) %>% \n    mutate(district = 1:13)\n\n\n\nAnd then to plot the standard stacked boxplots, you would need to add the reference plan manually to the rest.\n\n\nsorted %>% ggplot(aes(x = district, y = DVS, group = district)) + \n  geom_boxplot() + \n  theme_minimal() + \n  labs(x = 'District, sorted by DVS') + \n  geom_segment(data = sorted_reference, size = 1,\n               aes(x = district - 0.35, xend = district + 0.35, \n                   yend = DVS, color = 'red')) + \n  scale_color_manual(name = '', values = c('red' = 'red'),\n  labels = c('ref'), guide = 'legend')\n\n\n\n\nStudying districts 1, 2, and 4\nThe steps between loading in data to your first simulation wasnâ€™t terrible in the old version when you were working with the full map. However, when trying to work with subsets, it became messy.\nFirst you needed to subset the shape and then rebuild a new adjacency graph that only had the remaining precincts.\n\n\nsub <- nc_shp %>% filter(cd_17 %in% c(1, 2, 4))\nsub_adj <- redist.adjacency(sub)\n\n\n\nThen, if your target on the full map was 1%, you had to compute the equivalent on the subset map, as a 1% population deviation on a subset is often larger once recombined with the full map.\n\n\npop_tol <- 0.01\nsubparpop <- sum(sub$pop)/3\nparpop <- sum(nc_shp$pop)/13\n\nsub_pop_tol <-  min(abs(subparpop - parpop * (1 - pop_tol)),\n                abs(subparpop - parpop * (1 + pop_tol))) / subparpop\nsub_pop_tol\n\n\n[1] 0.0096399\n\nNow we can simulate again, but on the smaller map.\n\n\nsims_sub <- redist.smc(adj = sub_adj, total_pop = sub$pop,\n                      nsims = 1000,  ndists = 3, \n                      counties = match(sub$county, unique(sub$county)),\n                      pop_tol = sub_pop_tol, silent = TRUE)\n\n\n\nAs before, we have to compute metrics for both the reference plan and the simulated plans.\n\n\nsub_metrics <- redist.metrics(plans = sims_sub$plans, measure = 'DVS', \n                              rvote = sub$el14g_uss_r, sub$el14g_uss_d)\n\nsub_sorted <- sub_metrics %>% \n  group_by(draw) %>% \n  arrange(DVS,.by_group = TRUE) %>% \n  mutate(district = 1:3) %>% \n  ungroup()\n\nsub_reference_metrics <- redist.metrics(plans = match(sub$cd_17, \n                                                      unique(sub$cd_17)), \n                                        measure = 'DVS', \n                                        rvote = sub$el14g_uss_r, \n                                        dvote = sub$el14g_uss_d)\n\nsub_sorted_reference <- sub_reference_metrics %>%\n    arrange(DVS) %>% \n    mutate(district = 1:3)\n\n\n\nAnd finally, we can plot the metrics and manually add the reference points.\n\n\nsub_sorted %>% ggplot(aes(x = district, y = DVS, group = district)) + \n  geom_boxplot() + \n  theme_minimal() + \n  labs(x = 'District, sorted by DVS') + \n  geom_segment(data = sub_sorted_reference, size = 1,\n               aes(x = district - 0.35, xend = district + 0.35, \n                   yend = DVS, color = 'red')) + \n  scale_color_manual(name = '', values = c('red' = 'red'),\n  labels = c('ref'), guide = 'legend')\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-04-02-redist-300/redist-300_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-04-07T07:58:43-07:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
