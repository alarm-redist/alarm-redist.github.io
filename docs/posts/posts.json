[
  {
    "path": "posts/2021-05-28-census-das/",
    "title": "Impact of the Census Disclosure Avoidance System on Redistricting",
    "description": "In attempting to protect the privacy of 2020 Census respondents, the Census \nBureau has made its data unsuitable for redistricting purposes.",
    "author": [
      {
        "name": "Christopher T. Kenny",
        "url": {}
      },
      {
        "name": "Shiro Kuriwaki",
        "url": {}
      },
      {
        "name": "Cory McCartan",
        "url": {}
      },
      {
        "name": "Evan Rosenman",
        "url": {}
      },
      {
        "name": "Tyler Simko",
        "url": {}
      },
      {
        "name": "Kosuke Imai",
        "url": {}
      }
    ],
    "date": "2021-05-28",
    "categories": [],
    "contents": "\nThe U.S. Census Bureau plans to protect the privacy of 2020 Census respondents through its Disclosure Avoidance System (DAS), which attempts to achieve differential privacy guarantees by adding noise to the Census data. The Bureau has asked for feedback on the adequacy of DAS-protected data for real-world purposes. The ALARM project has conducted an extensive analysis into how the DAS-protected data affects redistricting and voting rights analyses, and has submitted these findings to the Census Bureau.\nRead the report: The Impact of the U.S. Census Disclosure Avoidance System on Redistricting and Voting Rights Analysis\"\nA figure from the report, indicating partisan biases in the DAS-protected data.By applying redistricting simulation and analysis methods to DAS-protected 2010 Census data, we find that the protected data are not of sufficient quality for redistricting purposes. Compared to the original Census 2010 data, we find that the DAS-protected data:\nPrevent map drawers from creating districts that satisfy the One Person, One Vote principle, according to current statutory and judicial standards. Actual deviations from equal population will generally be several times larger than as reported under the DAS data. The magnitude of this problem increases for smaller districts such as state legislative districts and school boards.\nTransfer population from low-turnout, mixed-party areas to high-turnout, single-party areas. This differential bias leads to different district boundaries, which in turn implies significant and unpredictable differences in election results. The discrepancy also degrades the ability of analysts to reliably identify partisan gerrymanders.\nTransfer population from racially mixed areas to racially segregated areas. This bias effectively means racially heterogeneous areas are under-counted. The degree of racial segregation can therefore be over-estimated, which can lead to a change in the number of majority-minority districts. It also creates significant precinct-level variability, which adds substantial unpredictability to whether or not a minority voter is included in a majority-minority district.\nAlter individual-level race predictions constructed from voter names and addresses. This leads to fewer estimated minority voters and majority-minority districts in a re-analysis of a recent Voting Rights Act case, NAACP v. East Ramapo School District. At a statewide level, however, the DAS data does not curb the ability of algorithms to identify the race of voters from names and addresses. Therefore, this casts doubt on the universal privacy protection guarantee of DAS data.\nOur primary recommendation is to release Census P.L. 94-171 data without using the Disclosure Avoidance System, and instead rely on a swapping method similar to that applied to the 2010 Census data in order to protect respondent privacy.\nIf the Census Bureau decides to apply the current DAS to Census PL. 94-171 Data, we recommend increasing the privacy loss budget and allocating the increase to improving redistricting outcomes. In particular, preserving the accuracy of populations at the voting tabulation district level would be critical. The Bureau must avoid injecting noise that systematically undercounts certain racial and partisan groups in the privacy-protected data. Additional recommendations are given in the paper.\n\n\n\n",
    "preview": "posts/2021-05-28-census-das/ex_plot.png",
    "last_modified": "2021-05-28T23:07:06-04:00",
    "input_file": {},
    "preview_width": 1500,
    "preview_height": 1200
  },
  {
    "path": "posts/2021-04-02-redist-300/",
    "title": "redist 3.0",
    "description": "A major release brings new algorithms, new workflows, and significant \nusability improvements.",
    "author": [
      {
        "name": "Cory McCartan",
        "url": "https://corymccartan.github.io/"
      },
      {
        "name": "Christopher Kenny",
        "url": "https://www.christophertkenny.com/"
      }
    ],
    "date": "2021-04-07",
    "categories": [],
    "contents": "\nThe ALARM Project is excited to announce the release of redist 3.0 on CRAN. This release brings with it new algorithms and major new workflow improvements, making redistricting analysis broadly accessible to data scientists everywhere.\n\nInstall the new version with install.packages(\"redist\").\nNew Features\nThis release includes far too many changes to list comprehensively. Key improvements and new features include:\nNew tidy interface, including new redist_map and redist_plans objects\nMerge-split MCMC now available in redist_mergesplit()\nShort burst MCMC optimization now available in redist_shortburst() along with scoring functions\nImproved Flip MCMC interface and performance improvements\nNew support for larger simulation size limits\nFunctions to freeze parts of a map and extract district cores\nNew VRA constraint\nMany new plotting functions\nConsistent function and argument names\nNew partisanship and compactnes metrics\nPerformance improvements to compactness calculations\nPlan comparison and classification in compare_plans() and classify_plans()\nNew iowa dataset and cleaned-up package data\nTo begin exploring the new features, check out the new Get Started vignette.\nWorkflow Example: North Carolina\nTo demonstrate the new redist workflow, we’ll run through a basic analysis of the 2017 congressional districts of the state of North Carolina, which were struck down as an unconstitutional partisan gerrymander in 2019.\nNew workflow\n\n\nlibrary(tidyverse)\nlibrary(redist)\n\ndownload.file(\"https://github.com/alarm-redist/redist-data/raw/main/data/nc.rds\",\n              data_path <- tempfile())\nnc_shp <- readRDS(data_path) %>%\n    select(vtd:vap, el14g_uss_r:geometry)\n\n\n\nUnder the new workflow, a redistricting analysis begins with a redist_map object, which defines the basic parameters of the redistricting problem. The redist_map() constructor builds the precinct adjacency graph which is required for redistricting simulation, and stores relevant metadata, such as the desired population parity tolerance and a reference to the existing districts. It also comes with helpful plotting functions.\n\n\nnc = redist_map(nc_shp, existing_plan=cd_17, pop_tol=0.01)\nprint(nc)\n\n\nA redist_map object with 2692 units and 15 fields\nTo be partitioned into 13 districts with population between 733,499 - 1.0% and 733,499 + 1.0%\nWith geometry:\n    bbox:           xmin: 406820 ymin: 2696.2 xmax: 3070200 ymax: 1043600\n    projected CRS:  NAD83(HARN) / North Carolina (ftUS)\n# A tibble: 2,692 x 15\n   vtd       county   pop   vap el14g_uss_r el14g_uss_d el14g_uss_l\n * <chr>     <chr>  <int> <int>       <int>       <int>       <int>\n 1 3700106W  37001   1973  1505         181         182          17\n 2 3700112E  37001   3391  2503         180         271          21\n 3 3700112W  37001   2744  2156         457         481          42\n 4 3700106N  37001   4468  3167         231         466          31\n 5 37001126  37001   2038  1713         670         416          38\n 6 37001124  37001   2455  1948         491         391          33\n 7 370011210 37001   2802  2127         358         309          31\n 8 3700103N  37001   5712  4955        1063         853          53\n 9 3700102   37001   4491  3483        1246         313          62\n10 3700106E  37001   3113  2371         423         432          42\n# … with 2,682 more rows, and 8 more variables: el14g_uss_wi <int>,\n#   el14g_uss_tot <int>, cd_13 <int>, cd_17 <int>, aland10 <dbl>,\n#   awater10 <dbl>, geometry <MULTIPOLYGON [US_survey_foot]>,\n#   adj <list>\n\nplot(nc, el14g_uss_d/(el14g_uss_d+el14g_uss_r)) +\n    scale_fill_gradient2(midpoint=0.5)\n\n\n\n\nOnce we’ve created a redist_map object, we can simulate redistricting plans.\n\n\nplans = redist_smc(nc, 1000, counties=county, silent=TRUE) # 1000 plans\nprint(plans)\n\n\n1000 sampled plans and 1 reference plan with 13 districts from a 2692-unit map,\n  drawn using Sequential Monte Carlo\nWith plans resampled from weights\nPlans matrix: num [1:2692, 1:1001] 6 6 6 6 6 6 6 6 6 6 ...\n# A tibble: 13,013 x 3\n   draw  district total_pop\n   <fct>    <int>     <dbl>\n 1 cd_17        1    733323\n 2 cd_17        2    734740\n 3 cd_17        3    732627\n 4 cd_17        4    733218\n 5 cd_17        5    733879\n 6 cd_17        6    733554\n 7 cd_17        7    734750\n 8 cd_17        8    734777\n 9 cd_17        9    731507\n10 cd_17       10    736057\n# … with 13,003 more rows\n\nThe plans variable is a redist_plans object—a special container designed to make handling sets of redistricting plans painless. As the output above shows, plans contains the 1,000 samppled plans, plus the 2017 congressional districts. We can plot a few of these plans.\n\n\nredist.plot.plans(plans, draws=c(\"cd_17\", \"1\", \"2\", \"3\"), geom=nc)\n\n\n\n\nA redist_plans object makes it easy to compute plan and district summary statistics.\n\n\nplans = plans %>%\n    mutate(comp = distr_compactness(nc),\n           dem_share = group_frac(nc, el14g_uss_d, el14g_uss_d + el14g_uss_r))\nprint(plans)\n\n\n1000 sampled plans and 1 reference plan with 13 districts from a 2692-unit map,\n  drawn using Sequential Monte Carlo\nWith plans resampled from weights\nPlans matrix: num [1:2692, 1:1001] 6 6 6 6 6 6 6 6 6 6 ...\n# A tibble: 13,013 x 5\n   draw  district total_pop  comp dem_share\n   <fct>    <int>     <dbl> <dbl>     <dbl>\n 1 cd_17        1    733323 0.803     0.687\n 2 cd_17        2    734740 0.803     0.443\n 3 cd_17        3    732627 0.803     0.407\n 4 cd_17        4    733218 0.803     0.674\n 5 cd_17        5    733879 0.803     0.425\n 6 cd_17        6    733554 0.803     0.441\n 7 cd_17        7    734750 0.803     0.446\n 8 cd_17        8    734777 0.803     0.439\n 9 cd_17        9    731507 0.803     0.440\n10 cd_17       10    736057 0.803     0.419\n# … with 13,003 more rows\n\nFrom there, we can quickly generate informative plots. First we check the compactness of the generated plans, and see that they are significantly more compact than the adopted 2017 plan.\n\n\nhist(plans, comp) +\n    labs(x=\"Compactness score (higher is more compact)\")\n\n\n\n\nNext, we look at the partisan implications of the 2017 plan. We plot the two-party Democratic vote share in each district, with districts sorted by this quantity. Each dot on the plot below is a district from one simulated plan, and the red lines show the values for the 2017 plan.\n\n\nredist.plot.distr_qtys(plans, dem_share, size=0.1)\n\n\n\n\nWe see immediately that the 2017 plan packs Democratic voters into the three most Democratic districts, and cracks them in the remaining 10 districts, leading to a durable 10–3 Republican-Democratic seat split (in an election which Democrats captured 49% of the statewide two-party vote). A clear partisan gerrymander.\nStudying districts 1, 2, and 4\nIf we want to study a specific set of districts, we can quickly filter() to the relevant map area and re-run the analysis. The redist_map() object will handle all appropriate adjustments to the adjacency graph, number of districts, and population tolerance (as is visible below).\n\n\nnc_sub = filter(nc, cd_17 %in% c(1, 2, 4))\nprint(nc_sub)\n\n\nA redist_map object with 571 units and 15 fields\nTo be partitioned into 3 districts with population between 733,760 - 1.0353% and 733,760 + 0.96399%\nWith geometry:\n    bbox:           xmin: 1921600 ymin: 524880 xmax: 2784100 ymax: 1028200\n    projected CRS:  NAD83(HARN) / North Carolina (ftUS)\n# A tibble: 571 x 15\n   vtd     county   pop   vap el14g_uss_r el14g_uss_d el14g_uss_l\n * <chr>   <chr>  <int> <int>       <int>       <int>       <int>\n 1 37015C2 37015   2182  1707         174         503          13\n 2 37015M1 37015   1103   849         172         167           5\n 3 37015C1 37015   1229   986         229         184          11\n 4 37015MH 37015    992   811         146         254          12\n 5 37015W2 37015    966   764         286          47          20\n 6 37015W1 37015   7005  5703         596        1190          44\n 7 37015M2 37015   1290   983          99         239          16\n 8 37015SN 37015   1410  1025          63         327          11\n 9 37015WH 37015   1554  1274         292         262          12\n10 37015WD 37015   1409  1050          35         319           5\n# … with 561 more rows, and 8 more variables: el14g_uss_wi <int>,\n#   el14g_uss_tot <int>, cd_13 <int>, cd_17 <int>, aland10 <dbl>,\n#   awater10 <dbl>, geometry <MULTIPOLYGON [US_survey_foot]>,\n#   adj <list>\n\nplot(nc_sub)\n\n\n\n\nOn this subset, too, the adopted 2017 plan is a significant outlier.\n\n\nplans_sub = redist_smc(nc_sub, 1000, counties=county, silent=T) %>%\n    mutate(dem_share = group_frac(nc_sub, el14g_uss_d, el14g_uss_d + el14g_uss_r))\nredist.plot.distr_qtys(plans_sub, dem_share, size=0.3)\n\n\n\n\nOld workflow\nIn comparison, the old workflow required significantly more steps and manual processing.\n\n\nlibrary(tidyverse)\nlibrary(redist)\n\ndownload.file(\"https://github.com/alarm-redist/redist-data/raw/main/data/nc.rds\",\n              data_path <- tempfile())\nnc_shp <- readRDS(data_path) %>%\n    select(vtd:vap, el14g_uss_r:geometry)\n\n\n\nOnce we’ve downloaded the data, we can start by building the adjacency graph.\n\n\nadj <- redist.adjacency(nc_shp)\n\n\n\nTime to first simulation was never really the issue, however each simulation required many inputs. redist_map objects keep track of the adj, total_pop, ndists, and pop_tol arguments, but in the older version, you had to specify each of these for every simulation. One of the quirky aspects of the older version was that counties needed to be a vector with values 1:n_counties, meaning that you had to manually transform it to use it and that only worked if the counties were contiguous.\n\n\nsims <- redist.smc(adj = adj, total_pop = nc_shp$pop, ndists = 13, \n                   pop_tol = 0.01, \n                   counties = match(nc_shp$county, unique(nc_shp$county)), \n                   nsims = 1000, silent = TRUE)\n\n\n\nOnce you finished simulating, setting up plots was always a hassle, as you needed to plot both the distribution of simulations and then compute the same metric separately for the reference plan, in this case that’s the 2017 congressional districts.\n\n\nmetrics <- redist.metrics(plans = sims$plans, measure = 'DVS',\n                          rvote = nc_shp$el14g_uss_r, nc_shp$el14g_uss_d)\n\nsorted <- metrics %>% \n  group_by(draw) %>% \n  arrange(DVS,.by_group = TRUE) %>% \n  mutate(district = 1:13) %>% \n  ungroup()\n\nreference_metrics <- redist.metrics(plans = nc_shp$cd_17, \n                                    measure = 'DVS', \n                                    rvote = nc_shp$el14g_uss_r, \n                                    dvote = nc_shp$el14g_uss_d)\n\nsorted_reference <- reference_metrics %>% \n    arrange(DVS) %>% \n    mutate(district = 1:13)\n\n\n\nAnd then to plot the standard stacked boxplots, you would need to add the reference plan manually to the rest.\n\n\nsorted %>% ggplot(aes(x = district, y = DVS, group = district)) + \n  geom_boxplot() + \n  theme_minimal() + \n  labs(x = 'District, sorted by DVS') + \n  geom_segment(data = sorted_reference, size = 1,\n               aes(x = district - 0.35, xend = district + 0.35, \n                   yend = DVS, color = 'red')) + \n  scale_color_manual(name = '', values = c('red' = 'red'),\n  labels = c('ref'), guide = 'legend')\n\n\n\n\nStudying districts 1, 2, and 4\nThe steps between loading in data to your first simulation wasn’t terrible in the old version when you were working with the full map. However, when trying to work with subsets, it became messy.\nFirst you needed to subset the shape and then rebuild a new adjacency graph that only had the remaining precincts.\n\n\nsub <- nc_shp %>% filter(cd_17 %in% c(1, 2, 4))\nsub_adj <- redist.adjacency(sub)\n\n\n\nThen, if your target on the full map was 1%, you had to compute the equivalent on the subset map, as a 1% population deviation on a subset is often larger once recombined with the full map.\n\n\npop_tol <- 0.01\nsubparpop <- sum(sub$pop)/3\nparpop <- sum(nc_shp$pop)/13\n\nsub_pop_tol <-  min(abs(subparpop - parpop * (1 - pop_tol)),\n                abs(subparpop - parpop * (1 + pop_tol))) / subparpop\nsub_pop_tol\n\n\n[1] 0.0096399\n\nNow we can simulate again, but on the smaller map.\n\n\nsims_sub <- redist.smc(adj = sub_adj, total_pop = sub$pop,\n                      nsims = 1000,  ndists = 3, \n                      counties = match(sub$county, unique(sub$county)),\n                      pop_tol = sub_pop_tol, silent = TRUE)\n\n\n\nAs before, we have to compute metrics for both the reference plan and the simulated plans.\n\n\nsub_metrics <- redist.metrics(plans = sims_sub$plans, measure = 'DVS', \n                              rvote = sub$el14g_uss_r, sub$el14g_uss_d)\n\nsub_sorted <- sub_metrics %>% \n  group_by(draw) %>% \n  arrange(DVS,.by_group = TRUE) %>% \n  mutate(district = 1:3) %>% \n  ungroup()\n\nsub_reference_metrics <- redist.metrics(plans = match(sub$cd_17, \n                                                      unique(sub$cd_17)), \n                                        measure = 'DVS', \n                                        rvote = sub$el14g_uss_r, \n                                        dvote = sub$el14g_uss_d)\n\nsub_sorted_reference <- sub_reference_metrics %>%\n    arrange(DVS) %>% \n    mutate(district = 1:3)\n\n\n\nAnd finally, we can plot the metrics and manually add the reference points.\n\n\nsub_sorted %>% ggplot(aes(x = district, y = DVS, group = district)) + \n  geom_boxplot() + \n  theme_minimal() + \n  labs(x = 'District, sorted by DVS') + \n  geom_segment(data = sub_sorted_reference, size = 1,\n               aes(x = district - 0.35, xend = district + 0.35, \n                   yend = DVS, color = 'red')) + \n  scale_color_manual(name = '', values = c('red' = 'red'),\n  labels = c('ref'), guide = 'legend')\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-04-02-redist-300/redist-300_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-04-07T10:58:43-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
