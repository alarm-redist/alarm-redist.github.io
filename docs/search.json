[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nDeveloping methodology and tools to analyze legislative redistricting.\n",
    "section": "",
    "text": "Developing methodology and tools to analyze legislative redistricting.\n\n\n\n\n\n\n\n50-State Redistricting Simulations\n\n\n\n\n\n\nComprehensive project to simulate alternative congressional redistricting plans for all fifty states in the 2022 redistricting cycle.\n\n\n Explore the project and data » \n\n\n\n\nThe Algorithm-Assisted Redistricting Methodology (ALARM) Project is a research team at Harvard University led by Kosuke Imai. It conducts research into redistricting sampling algorithms, best practices and workflows for redistricting analysis, and tools to visualize, explore, and understand redistricting plans.\n\n\n\nredist: Simulation Methods for Legislative Redistricting\n\n\n\nEnables researchers to sample redistricting plans from a pre-specified target distribution using state-of-the-art algorithms. Implements a wide variety constraints in the redistricting process, such as geographic compactness and population parity requirements. Tools for analysis such as computation of various summary statistics and plotting functionality are also included.\n\n\n Go to package home page » \n\n\n\n\n\n2020 Redistricting Data Files\n\n\n\nPrecinct-level demographic and election data from the 2020 decennial census and the Voting and Election Science Team which have been tidied and joined together using 2020 precinct boundaries.\n\n\n Access the data » \n\n\n\n\n\n\n\n\n\n\n\n\nWorking Paper: Evaluating Bias and Noise Induced by the U.S. Census Bureau’s Privacy Protection Methods\n\n\n\n\n\nOur new working paper uses the new Noisy Measurement File release to understand bias and noise caused by swapping (1990-2010) and the TopDown algorithm (2020). \n\n\n\n\n\nJun 14, 2023\n\n\nChristopher T. Kenny, Shiro Kuriwaki, Cory McCartan, Tyler Simko, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nWidespread Partisan Gerrymandering Mostly Cancels Nationally, but Reduces Electoral Competition Published in PNAS\n\n\n\n\n\nOur paper which details gerrymandering and partisan fairness in the 2022 redistricting maps is now published in PNAS. \n\n\n\n\n\nJun 13, 2023\n\n\nChristopher T. Kenny, Cory McCartan, Tyler Simko, Shiro Kuriwaki, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nLetter: Researchers need better access to US Census data published in Science\n\n\n\n\n\nOur letter providing recommendations to the Census Bureau about the Noisy Measurements File (NMF) now published in Science. \n\n\n\n\n\nJun 3, 2023\n\n\nCory McCartan, Tyler Simko, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nWidespread Partisan Gerrymandering Mostly Cancels Nationally, but Reduces Electoral Competition Forthcoming in PNAS\n\n\n\n\n\nOur paper describing partisan gerrymandering and competition in the 2022 US congressional districts is now forthcoming in PNAS. \n\n\n\n\n\nApr 14, 2023\n\n\nChristopher T. Kenny, Cory McCartan, Tyler Simko, Shiro Kuriwaki, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nredist 4.1\n\n\n\n\n\nA medium-sized release with more flexible plotting, better diagnostics, and speed improvements. \n\n\n\n\n\nMar 19, 2023\n\n\nChristopher T. Kenny, Cory McCartan\n\n\n\n\n\n\n\n\n\n\n\n\nComment: The Essential Role of Policy Evaluation for the 2020 Census Disclosure Avoidance System\n\n\n\n\n\nOur response to boyd and Sarathy (2022) is now published in the HDSR! \n\n\n\n\n\nJan 31, 2023\n\n\nChristopher T. Kenny, Shiro Kuriwaki, Cory McCartan, Evan Rosenman, Tyler Simko, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nredist Recieved POLMETH’s 2022 Statistical Software Award\n\n\n\n\n\nOur software won the Society for Political Methodology’s Statistical Software Award. \n\n\n\n\n\nDec 15, 2022\n\n\nChristopher T. Kenny, Cory McCartan, Ben Fifield, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\n50statesSimulations in Nature Scientific Data\n\n\n\n\n\nNow published at Nature Scientific Data. \n\n\n\n\n\nNov 14, 2022\n\n\nCory McCartan, Christopher T. Kenny, Tyler Simko, George Garcia III, Kevin Wang, Melissa Wu, Shiro Kuriwaki, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nComment: The Essential Role of Policy Evaluation for the 2020 Census Disclosure Avoidance System\n\n\n\n\n\nWe’re excited to announce our forthcoming article discussing boyd and Sarathy (2022). \n\n\n\n\n\nOct 18, 2022\n\n\nChristopher T. Kenny, Shiro Kuriwaki, Cory McCartan, Evan Rosenman, Tyler Simko, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\n‘One vote disparity’ can be improved with state-of-the-art algorithms\n\n\n\n\n\nOur article in Nikkei Business on reducing Japanese malapportionment was released! \n\n\n\n\n\nSep 30, 2022\n\n\nKosuke Imai, Kento Yamada, Rei Yatsuhashi, Sho Miyazaki\n\n\n\n\n\n\n\n\n\n\n\n\nWidespread Partisan Gerrymandering Mostly Cancels Nationally, but Reduces Electoral Competition\n\n\n\n\n\nGerrymandering in 2020 redistricting makes the US House elections less competitive, but net seat gains are small nationally. The partisan bias of the enacted national map is about as biased as non-partisan simulations, due to geography and legal requirements. \n\n\n\n\n\nAug 16, 2022\n\n\nChristopher T. Kenny, Cory McCartan, Tyler Simko, Shiro Kuriwaki, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nFifty States Data Descriptor\n\n\n\n\n\nA detailed description of the 50-State Redistricting Simulations and new software to help you use them. \n\n\n\n\n\nJul 28, 2022\n\n\nCory McCartan, Christopher T. Kenny, Tyler Simko, George Garcia III, Kevin Wang, Melissa Wu, Shiro Kuriwaki, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\n47-Prefectures at the Japanese Society of Quantitative Political Science\n\n\n\n\n\nWe are presenting Friday on malapportionment. 私たちは、アルゴリズムを用いた一票の格差の是正について、金曜日に発表します。 \n\n\n\n\n\nJul 7, 2022\n\n\nSho Miyazaki, Kento Yamada, Rei Yatsuhashi, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nredist 4.0\n\n\n\n\n\nA major release with big changes to constraints and diagnostics. \n\n\n\n\n\nJun 20, 2022\n\n\nChristopher T. Kenny, Cory McCartan\n\n\n\n\n\n\n\n\n\n\n\n\n47-Prefecture Project\n\n\n\n\n\nUsing redistricting simulation methods to better understand redistricting in Japan. \n\n\n\n\n\nApr 23, 2022\n\n\nSho Miyazaki, Kento Yamada, Rei Yatsuhashi, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nRevised and published: The use of differential privacy for census data and its impact on redistricting\n\n\n\n\n\nA new postscript analyzes the final version of the U.S. Census Bureau’s Disclosure Avoidance System. \n\n\n\n\n\nOct 7, 2021\n\n\nChristopher T. Kenny, Shiro Kuriwaki, Cory McCartan, Evan Rosenman, Tyler Simko, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\n2020 Redistricting Data Files\n\n\n\n\n\nCensus and election data joined together for use in redistricting and voting rights analysis. \n\n\n\n\n\nAug 10, 2021\n\n\nChristopher T. Kenny, Cory McCartan\n\n\n\n\n\n\n\n\n\n\n\n\nRevised: Impact of the Census Disclosure Avoidance System\n\n\n\n\n\nWe are releasing an updated version of our analysis of the U.S. Census’ privacy protection system and its impacts on the redistricting process. \n\n\n\n\n\nJul 5, 2021\n\n\nChristopher T. Kenny, Shiro Kuriwaki, Cory McCartan, Evan Rosenman, Tyler Simko, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nReaction to the Census Bureau’s Updated Parameters\n\n\n\n\n\nThe Data Stewardship Executive Policy Committee announces a higher privacy loss budget and other changes to the Disclosure Avoidance System. \n\n\n\n\n\nJun 9, 2021\n\n\nChristopher T. Kenny, Shiro Kuriwaki, Cory McCartan, Evan Rosenman, Tyler Simko, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nFAQ: Impact of the Census Disclosure Avoidance System\n\n\n\n\n\nAnswers to common questions about our recently-released report evaluating the Census’ Disclosure Avoidance System. \n\n\n\n\n\nJun 2, 2021\n\n\nChristopher T. Kenny, Shiro Kuriwaki, Cory McCartan, Evan Rosenman, Tyler Simko, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nImpact of the Census Disclosure Avoidance System on Redistricting\n\n\n\n\n\nIn attempting to protect the privacy of 2020 Census respondents, the Census Bureau has made its data unsuitable for redistricting purposes. \n\n\n\n\n\nMay 28, 2021\n\n\nChristopher T. Kenny, Shiro Kuriwaki, Cory McCartan, Evan Rosenman, Tyler Simko, Kosuke Imai\n\n\n\n\n\n\n\n\n\n\n\n\nredist 3.0\n\n\n\n\n\nA major release brings new algorithms, new workflows, and significant usability improvements. \n\n\n\n\n\nApr 7, 2021\n\n\nCory McCartan, Christopher Kenny\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-04-02-redist-300/redist-300.html",
    "href": "posts/2021-04-02-redist-300/redist-300.html",
    "title": "redist 3.0",
    "section": "",
    "text": "The ALARM Project is excited to announce the release of redist 3.0 on CRAN. This release brings with it new algorithms and major new workflow improvements, making redistricting analysis broadly accessible to data scientists everywhere.\nInstall the new version with install.packages(\"redist\")."
  },
  {
    "objectID": "posts/2021-04-02-redist-300/redist-300.html#new-workflow",
    "href": "posts/2021-04-02-redist-300/redist-300.html#new-workflow",
    "title": "redist 3.0",
    "section": "New workflow",
    "text": "New workflow\n\nlibrary(tidyverse)\nlibrary(redist)\n\ndownload.file(\"https://github.com/alarm-redist/redist-data/raw/main/data/nc.rds\",\n              data_path &lt;- tempfile())\nnc_shp &lt;- readRDS(data_path) %&gt;%\n    select(vtd:vap, el14g_uss_r:geometry)\n\nUnder the new workflow, a redistricting analysis begins with a redist_map object, which defines the basic parameters of the redistricting problem. The redist_map() constructor builds the precinct adjacency graph which is required for redistricting simulation, and stores relevant metadata, such as the desired population parity tolerance and a reference to the existing districts. It also comes with helpful plotting functions.\n\nnc = redist_map(nc_shp, existing_plan=cd_17, pop_tol=0.01)\nprint(nc)\n\nTo be partitioned into 13 districts with population between 733,498.7 - 1.0% and 733,498.7 + 1.0%\nWith geometry:\n    bbox:           xmin: 406819.6 ymin: 2696.2 xmax: 3070217 ymax: 1043629\n    projected CRS:  NAD83(HARN) / North Carolina (ftUS)\n# A tibble: 2,692 × 15\n   vtd       county   pop   vap el14g_uss_r el14g_uss_d el14g_uss_l el14g_uss_wi\n * &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt; &lt;int&gt;       &lt;int&gt;       &lt;int&gt;       &lt;int&gt;        &lt;int&gt;\n 1 3700106W  37001   1973  1505         181         182          17            1\n 2 3700112E  37001   3391  2503         180         271          21            0\n 3 3700112W  37001   2744  2156         457         481          42            1\n 4 3700106N  37001   4468  3167         231         466          31            2\n 5 37001126  37001   2038  1713         670         416          38            0\n 6 37001124  37001   2455  1948         491         391          33            1\n 7 370011210 37001   2802  2127         358         309          31            0\n 8 3700103N  37001   5712  4955        1063         853          53            3\n 9 3700102   37001   4491  3483        1246         313          62            2\n10 3700106E  37001   3113  2371         423         432          42            4\n# ℹ 2,682 more rows\n# ℹ 7 more variables: el14g_uss_tot &lt;int&gt;, cd_13 &lt;int&gt;, cd_17 &lt;int&gt;,\n#   aland10 &lt;dbl&gt;, awater10 &lt;dbl&gt;, geometry &lt;MULTIPOLYGON [US_survey_foot]&gt;,\n#   adj &lt;list&gt;\n\nplot(nc, el14g_uss_d/(el14g_uss_d+el14g_uss_r)) +\n    scale_fill_gradient2(midpoint=0.5)\n\n\n\n\n\n\n\n\nOnce we’ve created a redist_map object, we can simulate redistricting plans.\n\nplans = redist_smc(nc, 1000, counties=county, silent=TRUE) # 1000 plans\nprint(plans)\n\nA &lt;redist_plans&gt; containing 1,000 sampled plans and 1 reference plan\n\n\nPlans have 13 districts from a 2,692-unit map, and were drawn using Sequential\nMonte Carlo.\n\n\nWith plans resampled from weights\nPlans matrix: int [1:2692, 1:1001] 1 1 1 1 1 1 1 1 1 1 ...\n# A tibble: 13,013 × 3\n   draw  district total_pop\n   &lt;fct&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 cd_17        1    733554\n 2 cd_17        2    733879\n 3 cd_17        3    731507\n 4 cd_17        4    732627\n 5 cd_17        5    733323\n 6 cd_17        6    734750\n 7 cd_17        7    736057\n 8 cd_17        8    733447\n 9 cd_17        9    734777\n10 cd_17       10    729710\n# ℹ 13,003 more rows\n\n\nThe plans variable is a redist_plans object—a special container designed to make handling sets of redistricting plans painless. As the output above shows, plans contains the 1,000 samppled plans, plus the 2017 congressional districts. We can plot a few of these plans.\n\n#| fig-width: 8\nredist.plot.plans(plans, draws=c(\"cd_17\", \"1\", \"2\", \"3\"), geom=nc)\n\nWarning in redist.plot.plans(plans, draws = c(\"cd_17\", \"1\", \"2\", \"3\"), geom = nc): 'geom' is deprecated.\nUse 'shp' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\n\n\n\n\nA redist_plans object makes it easy to compute plan and district summary statistics.\n\nplans = plans %&gt;%\n    mutate(comp = distr_compactness(nc),\n           dem_share = group_frac(nc, el14g_uss_d, el14g_uss_d + el14g_uss_r))\n\nWarning: There were 2 warnings in `\"draw\" %in% names(data)`.\nThe first warning was:\nℹ In argument: `comp = distr_compactness(nc)`.\nCaused by warning in `distr_compactness()`:\n! 'distr_compactness' is deprecated.\nSee help(\"Deprecated\")\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\nprint(plans)\n\nA &lt;redist_plans&gt; containing 1,000 sampled plans and 1 reference plan\n\n\nPlans have 13 districts from a 2,692-unit map, and were drawn using Sequential\nMonte Carlo.\n\n\nWith plans resampled from weights\nPlans matrix: int [1:2692, 1:1001] 1 1 1 1 1 1 1 1 1 1 ...\n# A tibble: 13,013 × 5\n   draw  district total_pop  comp dem_share\n   &lt;fct&gt;    &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 cd_17        1    733554 0.951     0.441\n 2 cd_17        2    733879 0.951     0.425\n 3 cd_17        3    731507 0.951     0.440\n 4 cd_17        4    732627 0.951     0.407\n 5 cd_17        5    733323 0.951     0.687\n 6 cd_17        6    734750 0.951     0.446\n 7 cd_17        7    736057 0.951     0.419\n 8 cd_17        8    733447 0.951     0.416\n 9 cd_17        9    734777 0.951     0.439\n10 cd_17       10    729710 0.951     0.458\n# ℹ 13,003 more rows\n\n\nFrom there, we can quickly generate informative plots. First we check the compactness of the generated plans, and see that they are significantly more compact than the adopted 2017 plan.\n\nhist(plans, comp) +\n    labs(x=\"Compactness score (higher is more compact)\")\n\n\n\n\n\n\n\n\nNext, we look at the partisan implications of the 2017 plan. We plot the two-party Democratic vote share in each district, with districts sorted by this quantity. Each dot on the plot below is a district from one simulated plan, and the red lines show the values for the 2017 plan.\n\n#| fig-width: 8\nredist.plot.distr_qtys(plans, dem_share, size=0.1)\n\n\n\n\n\n\n\n\nWe see immediately that the 2017 plan packs Democratic voters into the three most Democratic districts, and cracks them in the remaining 10 districts, leading to a durable 10–3 Republican-Democratic seat split (in an election which Democrats captured 49% of the statewide two-party vote). A clear partisan gerrymander.\n\nStudying districts 1, 2, and 4\nIf we want to study a specific set of districts, we can quickly filter() to the relevant map area and re-run the analysis. The redist_map() object will handle all appropriate adjustments to the adjacency graph, number of districts, and population tolerance (as is visible below).\n\nnc_sub = filter(nc, cd_17 %in% c(1, 2, 4))\nprint(nc_sub)\n\nA &lt;redist_map&gt; with 571 units and 15 fields\n\n\nTo be partitioned into 3 districts with population between 733,498.7 - 1.0% and 733,498.7 + 1.0%\nWith geometry:\n    bbox:           xmin: 1921644 ymin: 524882.4 xmax: 2784102 ymax: 1028248\n    projected CRS:  NAD83(HARN) / North Carolina (ftUS)\n# A tibble: 571 × 15\n   vtd     county   pop   vap el14g_uss_r el14g_uss_d el14g_uss_l el14g_uss_wi\n * &lt;chr&gt;   &lt;chr&gt;  &lt;int&gt; &lt;int&gt;       &lt;int&gt;       &lt;int&gt;       &lt;int&gt;        &lt;int&gt;\n 1 37015C2 37015   2182  1707         174         503          13            0\n 2 37015M1 37015   1103   849         172         167           5            0\n 3 37015C1 37015   1229   986         229         184          11            0\n 4 37015MH 37015    992   811         146         254          12            0\n 5 37015W2 37015    966   764         286          47          20            0\n 6 37015W1 37015   7005  5703         596        1190          44            2\n 7 37015M2 37015   1290   983          99         239          16            0\n 8 37015SN 37015   1410  1025          63         327          11            0\n 9 37015WH 37015   1554  1274         292         262          12            0\n10 37015WD 37015   1409  1050          35         319           5            0\n# ℹ 561 more rows\n# ℹ 7 more variables: el14g_uss_tot &lt;int&gt;, cd_13 &lt;int&gt;, cd_17 &lt;int&gt;,\n#   aland10 &lt;dbl&gt;, awater10 &lt;dbl&gt;, geometry &lt;MULTIPOLYGON [US_survey_foot]&gt;,\n#   adj &lt;list&gt;\n\nplot(nc_sub)\n\n\n\n\n\n\n\n\nOn this subset, too, the adopted 2017 plan is a significant outlier.\n\nplans_sub = redist_smc(nc_sub, 1000, counties=county, silent=T) %&gt;%\n    mutate(dem_share = group_frac(nc_sub, el14g_uss_d, el14g_uss_d + el14g_uss_r))\nredist.plot.distr_qtys(plans_sub, dem_share, size=0.3)"
  },
  {
    "objectID": "posts/2021-04-02-redist-300/redist-300.html#old-workflow",
    "href": "posts/2021-04-02-redist-300/redist-300.html#old-workflow",
    "title": "redist 3.0",
    "section": "Old workflow",
    "text": "Old workflow\nIn comparison, the old workflow required significantly more steps and manual processing.\n\nlibrary(tidyverse)\nlibrary(redist)\n\ndownload.file(\"https://github.com/alarm-redist/redist-data/raw/main/data/nc.rds\",\n              data_path &lt;- tempfile())\nnc_shp &lt;- readRDS(data_path) %&gt;%\n    select(vtd:vap, el14g_uss_r:geometry)\n\nOnce we’ve downloaded the data, we can start by building the adjacency graph.\n\nadj &lt;- redist.adjacency(nc_shp)\n\nTime to first simulation was never really the issue, however each simulation required many inputs. redist_map objects keep track of the adj, total_pop, ndists, and pop_tol arguments, but in the older version, you had to specify each of these for every simulation. One of the quirky aspects of the older version was that counties needed to be a vector with values 1:n_counties, meaning that you had to manually transform it to use it and that only worked if the counties were contiguous.\n\nsims &lt;- redist.smc(adj = adj, total_pop = nc_shp$pop, ndists = 13,\n                   pop_tol = 0.01,\n                   counties = match(nc_shp$county, unique(nc_shp$county)),\n                   nsims = 1000, silent = TRUE)\n\nOnce you finished simulating, setting up plots was always a hassle, as you needed to plot both the distribution of simulations and then compute the same metric separately for the reference plan, in this case that’s the 2017 congressional districts.\n\nmetrics &lt;- redist.metrics(plans = sims$plans, measure = 'DVS',\n                          rvote = nc_shp$el14g_uss_r, nc_shp$el14g_uss_d)\n\nWarning in redist.metrics(plans = sims$plans, measure = \"DVS\", rvote = nc_shp$el14g_uss_r, : 'redist.metrics' is deprecated.\nUse 'part_dvs' instead.\nSee help(\"Deprecated\")\n\nsorted &lt;- metrics %&gt;%\n  group_by(draw) %&gt;%\n  arrange(DVS,.by_group = TRUE) %&gt;%\n  mutate(district = 1:13) %&gt;%\n  ungroup()\n\nreference_metrics &lt;- redist.metrics(plans = nc_shp$cd_17,\n                                    measure = 'DVS',\n                                    rvote = nc_shp$el14g_uss_r,\n                                    dvote = nc_shp$el14g_uss_d)\n\nWarning in redist.metrics(plans = nc_shp$cd_17, measure = \"DVS\", rvote = nc_shp$el14g_uss_r, : 'redist.metrics' is deprecated.\nUse 'part_dvs' instead.\nSee help(\"Deprecated\")\n\nsorted_reference &lt;- reference_metrics %&gt;%\n    arrange(DVS) %&gt;%\n    mutate(district = 1:13)\n\nAnd then to plot the standard stacked boxplots, you would need to add the reference plan manually to the rest.\n\nsorted %&gt;% ggplot(aes(x = district, y = DVS, group = district)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(x = 'District, sorted by DVS') +\n  geom_segment(data = sorted_reference, size = 1,\n               aes(x = district - 0.35, xend = district + 0.35,\n                   yend = DVS, color = 'red')) +\n  scale_color_manual(name = '', values = c('red' = 'red'),\n  labels = c('ref'), guide = 'legend')\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\nStudying districts 1, 2, and 4\nThe steps between loading in data to your first simulation wasn’t terrible in the old version when you were working with the full map. However, when trying to work with subsets, it became messy.\nFirst you needed to subset the shape and then rebuild a new adjacency graph that only had the remaining precincts.\n\nsub &lt;- nc_shp %&gt;% filter(cd_17 %in% c(1, 2, 4))\nsub_adj &lt;- redist.adjacency(sub)\n\nThen, if your target on the full map was 1%, you had to compute the equivalent on the subset map, as a 1% population deviation on a subset is often larger once recombined with the full map.\n\npop_tol &lt;- 0.01\nsubparpop &lt;- sum(sub$pop)/3\nparpop &lt;- sum(nc_shp$pop)/13\n\nsub_pop_tol &lt;-  min(abs(subparpop - parpop * (1 - pop_tol)),\n                abs(subparpop - parpop * (1 + pop_tol))) / subparpop\nsub_pop_tol\n\n[1] 0.009639859\n\n\nNow we can simulate again, but on the smaller map.\n\nsims_sub &lt;- redist.smc(adj = sub_adj, total_pop = sub$pop,\n                      nsims = 1000,  ndists = 3,\n                      counties = match(sub$county, unique(sub$county)),\n                      pop_tol = sub_pop_tol, silent = TRUE)\n\nAs before, we have to compute metrics for both the reference plan and the simulated plans.\n\nsub_metrics &lt;- redist.metrics(plans = sims_sub$plans, measure = 'DVS',\n                              rvote = sub$el14g_uss_r, sub$el14g_uss_d)\n\nWarning in redist.metrics(plans = sims_sub$plans, measure = \"DVS\", rvote = sub$el14g_uss_r, : 'redist.metrics' is deprecated.\nUse 'part_dvs' instead.\nSee help(\"Deprecated\")\n\nsub_sorted &lt;- sub_metrics %&gt;%\n  group_by(draw) %&gt;%\n  arrange(DVS,.by_group = TRUE) %&gt;%\n  mutate(district = 1:3) %&gt;%\n  ungroup()\n\nsub_reference_metrics &lt;- redist.metrics(plans = match(sub$cd_17,\n                                                      unique(sub$cd_17)),\n                                        measure = 'DVS',\n                                        rvote = sub$el14g_uss_r,\n                                        dvote = sub$el14g_uss_d)\n\nWarning in redist.metrics(plans = match(sub$cd_17, unique(sub$cd_17)), measure = \"DVS\", : 'redist.metrics' is deprecated.\nUse 'part_dvs' instead.\nSee help(\"Deprecated\")\n\nsub_sorted_reference &lt;- sub_reference_metrics %&gt;%\n    arrange(DVS) %&gt;%\n    mutate(district = 1:3)\n\nAnd finally, we can plot the metrics and manually add the reference points.\n\nsub_sorted %&gt;% ggplot(aes(x = district, y = DVS, group = district)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(x = 'District, sorted by DVS') +\n  geom_segment(data = sub_sorted_reference, size = 1,\n               aes(x = district - 0.35, xend = district + 0.35,\n                   yend = DVS, color = 'red')) +\n  scale_color_manual(name = '', values = c('red' = 'red'),\n  labels = c('ref'), guide = 'legend')"
  },
  {
    "objectID": "posts/2023-06-13-widespread-gerrymandering-pnas/widespread-gerrymandering-pnas.html",
    "href": "posts/2023-06-13-widespread-gerrymandering-pnas/widespread-gerrymandering-pnas.html",
    "title": "Widespread Partisan Gerrymandering Mostly Cancels Nationally, but Reduces Electoral Competition Published in PNAS",
    "section": "",
    "text": "Today, our paper Widespread Partisan Gerrymandering Mostly Cancels Nationally, but Reduces Electoral Competition was published in PNAS.\nWe evaluate partisan gerrymandering nationwide for new 2020 districts using simulated maps that account for geography and state-specific rules. We find evidence that gerrymandering is widespread across states, resulting in disadvantages for the Democratic party and less competitive districts. Read the abstract below:\n\nRedistricting plans in legislatures determine how voters’ preferences are translated into representative’s seats. Political parties may manipulate the redistricting process to gain additional seats and insulate incumbents from electoral competition, a process known as gerrymandering. But detecting gerrymandering is difficult without a representative set of alternative plans that comply with the same geographic and legal constraints. Harnessing recent algorithmic advances in sampling, we study such a collection of alternative redistricting plans that can serve as a non-partisan baseline. This methodological approach can distinguish electoral bias due to partisan effects from electoral bias due to other factors. We find that Democrats are structurally and geographically disadvantaged in House elections by 8 seats, while partisan gerrymandering disadvantages them by 2 seats.\n\nIf you’re interested in further details on this research project, take a look at the Supplementary Information or our replication data.\nThis research would not be possible without the 50-State Redistricting Simulations. A special thank you to George Garcia, Kevin Wang, and Melissa Wu."
  },
  {
    "objectID": "posts/2023-04-14-widespread-gerrymandering-in-pnas/widespread-gerrymandering-in-pnas.html",
    "href": "posts/2023-04-14-widespread-gerrymandering-in-pnas/widespread-gerrymandering-in-pnas.html",
    "title": "Widespread Partisan Gerrymandering Mostly Cancels Nationally, but Reduces Electoral Competition Forthcoming in PNAS",
    "section": "",
    "text": "We are delighted to announce that “Widespread Partisan Gerrymandering Mostly Cancels Nationally, but Reduces Electoral Competition” has been accepted for publication in PNAS, the Proceedings of the National Academy of Sciences of the United States of America. This article evaluates the partisan effects of redistricting in 2020 using simulations, allowing us to account for both compliance with legal requirements and the effects of political geography. While many individual state plans are biased in favor of one party or the other, the US House plan for 2022 is relatively unbiased. However, many districts are quite a bit less competitive than would be typically expected.\nA pre-print of the article is available on arXiv.\nWe are grateful to the editors and reviewers for their helpful feedback in improving this paper."
  },
  {
    "objectID": "posts/2023-01-31-comment-the-essenital-role-of-policy-evaluation/comment-the-essenital-role-of-policy-evaluation.html",
    "href": "posts/2023-01-31-comment-the-essenital-role-of-policy-evaluation/comment-the-essenital-role-of-policy-evaluation.html",
    "title": "Comment: The Essential Role of Policy Evaluation for the 2020 Census Disclosure Avoidance System",
    "section": "",
    "text": "We’re excited to share that Comment: The Essential Role of Policy Evaluation for the 2020 Census Disclosure Avoidance System is now available at the Harvard Data Science Review. We discuss boyd and Sarathy (2022), addressing both factual inaccuracies in their work and their contention that disagreements over privacy in the 2020 Census are primarily academic issues.\n\nIn “Differential Perspectives: Epistemic Disconnects Surrounding the U.S. Census Bureau’s Use of Differential Privacy,” boyd and Sarathy argue that empirical evaluations of the Census Disclosure Avoidance System (DAS), including our published analysis (Kenny et al., 2021b), failed to recognize that the benchmark data against which the 2020 DAS was evaluated is never a ground truth of population counts. In this commentary, we explain why policy evaluation, which was the main goal of our analysis, is still meaningful without access to a perfect ground truth. We also point out that our evaluation leveraged features specific to the decennial census and redistricting data, such as block-level population invariance under swapping and voter file racial identification, better approximating a comparison with the ground truth. Lastly, we show that accurate statistical predictions of individual race based on the Bayesian Improved Surname Geocoding, while not a violation of differential privacy, substantially increases the disclosure risk of private information the Census Bureau sought to protect. We conclude by arguing that policymakers must confront a key trade-off between data utility and privacy protection, and an epistemic disconnect alone is insufficient to explain disagreements between policy choices."
  },
  {
    "objectID": "posts/2022-11-01-50statessimulations/50statessimulations.html",
    "href": "posts/2022-11-01-50statessimulations/50statessimulations.html",
    "title": "50statesSimulations in Nature Scientific Data",
    "section": "",
    "text": "We’re excited to share that our article, Simulated redistricting plans for the analysis and evaluation of redistricting in the United States, is now available through Nature Scientific Data. This is a great step in making alternative redistricting plans more available for the public and researchers.\nCheck out the alarmdata R package for some helpers for working with this data!\nWant more information? Take a look at the blog post that accompanied the release of the original working paper or an early use of this data."
  },
  {
    "objectID": "posts/2022-09-30-nikkei/nikkei.html",
    "href": "posts/2022-09-30-nikkei/nikkei.html",
    "title": "‘One vote disparity’ can be improved with state-of-the-art algorithms",
    "section": "",
    "text": "ALARMプロジェクトは、日経ビジネスの依頼を受け、衆議院の区割り改定案の作成とその分析の記事を寄稿しました。区割りシミュレーションアルゴリズムの活用により、区画審の改定案よりも、市区町村の分割数と一票の格差が少なくなる区割り案が作成できます。https://business.nikkei.com/atcl/gen/19/00351/092100048/\nWe were invited to contribute to Nikkei Business (Japan)! We show that the SMC redistricting simulation algorithm can be used to reduce malapportionment without splitting more municipalities, when compared to the districting plan proposed by the commission. https://business.nikkei.com/atcl/gen/19/00351/092100048/"
  },
  {
    "objectID": "posts/2022-07-06-japanese-society-of-quantitative-political-science/japanese-society-of-quantitative-political-science.html",
    "href": "posts/2022-07-06-japanese-society-of-quantitative-political-science/japanese-society-of-quantitative-political-science.html",
    "title": "47-Prefectures at the Japanese Society of Quantitative Political Science",
    "section": "",
    "text": "We are presenting a poster presentation at the Japanese Society of Quantitative Political Science r emo::ji('jp')! We show that the well-known malapportionment (一票の格差) of the Japanese House of Representatives can be redressed without splitting administrative boundaries.\nALARMプロジェクトは、計量・数理政治研究会（JSQPS）の夏季集会にてポスターセッションに参加致します。アルゴリズムを衆議院の選挙区改変に応用して、市区町村の分割数を増やさなくても、一票の格差が是正される区割り案を作成できることを発表します。\nView the poster! Or see the full details of the project.\nポスターをご覧ください！ 詳細は、本プロジェクトのウェブサイトをご確認ください。"
  },
  {
    "objectID": "posts/2022-06-20-redist-40/redist-40.html",
    "href": "posts/2022-06-20-redist-40/redist-40.html",
    "title": "redist 4.0",
    "section": "",
    "text": "We are excited to announce the arrival of redist 4.0.1 on CRAN. This update focuses on increasing constraint consistency and diagnostic usability. The new tools here have been thoroughly tested as part of the 50-State Redistricting Simulations project.\nTo install the new version, run install.packages('redist')."
  },
  {
    "objectID": "posts/2022-06-20-redist-40/redist-40.html#footnotes",
    "href": "posts/2022-06-20-redist-40/redist-40.html#footnotes",
    "title": "redist 4.0",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor a very brief intro to redist_maps, see the 3.0 release post at https://alarm-redist.github.io/posts/2021-04-02-redist-300/.↩︎"
  },
  {
    "objectID": "posts/2021-10-06-2021-10-06-das-published/2021-10-06-das-published.html",
    "href": "posts/2021-10-06-2021-10-06-das-published/2021-10-06-das-published.html",
    "title": "Revised and published: The use of differential privacy for census data and its impact on redistricting",
    "section": "",
    "text": "At the end of May, the ALARM Project released a report examining “The Impact U.S. Census Disclosure Avoidance System on Redistricting and Voting Rights Analysis.” The Census Bureau has since updated the system parameters and released 2020 Census Data protected under this Disclosure Avoidance System.\nOur original report has been revised to include an analysis of the new system parameters, and appears today in the journal Science Advances.\nRead the paper: The use of differential privacy for census data and its impact on redistricting: The case of the 2020 U.S. Census"
  },
  {
    "objectID": "posts/2021-08-10-census-2020/census-2020.html",
    "href": "posts/2021-08-10-census-2020/census-2020.html",
    "title": "2020 Redistricting Data Files",
    "section": "",
    "text": "Warning in readLines(\"state-svg-defs.svg\"): incomplete final line found on\n'state-svg-defs.svg'\n\n\n               AK                        AL                        AR                        AZ                        CA                        CO                        CT                        DE                        FL                        GA                        HI                        IA                        ID                        IL                        IN                        KS                        KY                        LA                        MA                        MD                        ME                        MI                        MN                        MO                        MS                        MT                        NC                        ND                        NE                        NH                        NJ                        NM                        NV                        NY                        OH                        OK                        OR                        PA                        RI                        SC                        SD                        TN                        TX                        UT                        VA                        VT                        WA                        WI                        WV                        WY                        DC                        USA\nThe ALARM Project is glad to provide precinct-level demographic and election data from the 2020 decennial census and the Voting and Election Science Team which have been tidied and joined together using 2020 precinct boundaries. Where 2020 precinct boundaries are not available, Census block-level data is provided instead, and where no VEST data is available, only demographic information is provided. Code to generate the data from these sources is included; the entire workflow is open-source and reproducible."
  },
  {
    "objectID": "posts/2021-08-10-census-2020/census-2020.html#getting-the-data",
    "href": "posts/2021-08-10-census-2020/census-2020.html#getting-the-data",
    "title": "2020 Redistricting Data Files",
    "section": "Getting the data",
    "text": "Getting the data\nDownload individual states’ data below, or download a ZIP of all the data here. Our repository also contains more detailed data, as well as code and instructions for programmatic downloading, adding shapefile geometries, and other use cases.\nPlease make sure to cite the Voting and Election Science Team and the U.S. Census Bureau. Consult the license for information on modifying and sharing the data and/or code.\n\n2020 state data\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n \n\nAlabama\n \nVTDs\n\n \n\n\n\n\n\n \nal_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nAlaska\n \nVTDs\n\n \n\n\n\n\n\n \nak_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nArizona\n \nVTDs\n\n \n\n\n\n\n\n \naz_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nArkansas\n \nVTDs\n\n \n\n\n\n\n\n \nar_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nCalifornia\n \nCensus blocks\n\n \n\n\n\n\n\n \nca_2020_block.csv\n\n\n\n\n\n\n\n \n\nColorado\n \nVTDs\n\n \n\n\n\n\n\n \nco_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nConnecticut\n \nVTDs\n\n \n\n\n\n\n\n \nct_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nDelaware\n \nVTDs\n\n \n\n\n\n\n\n \nde_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nDistrict of Columbia\n \nVTDs\n\n \n\n\n\n\n\n \ndc_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nFlorida\n \nVTDs\n\n \n\n\n\n\n\n \nfl_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nGeorgia\n \nVTDs\n\n \n\n\n\n\n\n \nga_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nHawaii\n \nCensus blocks\n\n \n\n\n\n\n\n \nhi_2020_block.csv\n\n\n\n\n\n\n\n \n\nIdaho\n \nVTDs\n\n \n\n\n\n\n\n \nid_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nIllinois\n \nVTDs\n\n \n\n\n\n\n\n \nil_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nIndiana\n \nVTDs\n\n \n\n\n\n\n\n \nin_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nIowa\n \nVTDs\n\n \n\n\n\n\n\n \nia_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nKansas\n \nVTDs\n\n \n\n\n\n\n\n \nks_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nKentucky\n \nVTDs\n\n \n\n\n\n\n\n \nky_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nLouisiana\n \nVTDs\n\n \n\n\n\n\n\n \nla_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nMaine\n \nVTDs\n\n \n\n\n\n\n\n \nme_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nMaryland\n \nVTDs\n\n \n\n\n\n\n\n \nmd_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nMassachusetts\n \nVTDs\n\n \n\n\n\n\n\n \nma_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nMichigan\n \nVTDs\n\n \n\n\n\n\n\n \nmi_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nMinnesota\n \nVTDs\n\n \n\n\n\n\n\n \nmn_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nMississippi\n \nVTDs\n\n \n\n\n\n\n\n \nms_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nMissouri\n \nVTDs\n\n \n\n\n\n\n\n \nmo_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nMontana\n \nVTDs\n\n \n\n\n\n\n\n \nmt_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nNebraska\n \nVTDs\n\n \n\n\n\n\n\n \nne_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nNevada\n \nVTDs\n\n \n\n\n\n\n\n \nnv_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nNew Hampshire\n \nVTDs\n\n \n\n\n\n\n\n \nnh_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nNew Jersey\n \nVTDs\n\n \n\n\n\n\n\n \nnj_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nNew Mexico\n \nVTDs\n\n \n\n\n\n\n\n \nnm_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nNew York\n \nVTDs\n\n \n\n\n\n\n\n \nny_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nNorth Carolina\n \nVTDs\n\n \n\n\n\n\n\n \nnc_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nNorth Dakota\n \nVTDs\n\n \n\n\n\n\n\n \nnd_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nOhio\n \nVTDs\n\n \n\n\n\n\n\n \noh_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nOklahoma\n \nVTDs\n\n \n\n\n\n\n\n \nok_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nOregon\n \nCensus blocks\n\n \n\n\n\n\n\n \nor_2020_block.csv\n\n\n\n\n\n\n\n \n\nPennsylvania\n \nVTDs\n\n \n\n\n\n\n\n \npa_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nRhode Island\n \nVTDs\n\n \n\n\n\n\n\n \nri_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nSouth Carolina\n \nVTDs\n\n \n\n\n\n\n\n \nsc_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nSouth Dakota\n \nVTDs\n\n \n\n\n\n\n\n \nsd_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nTennessee\n \nVTDs\n\n \n\n\n\n\n\n \ntn_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nTexas\n \nVTDs\n\n \n\n\n\n\n\n \ntx_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nUtah\n \nVTDs\n\n \n\n\n\n\n\n \nut_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nVermont\n \nVTDs\n\n \n\n\n\n\n\n \nvt_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nVirginia\n \nVTDs\n\n \n\n\n\n\n\n \nva_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nWashington\n \nVTDs\n\n \n\n\n\n\n\n \nwa_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nWest Virginia\n \nVTDs\n\n \n\n\n\n\n\n \nwv_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nWisconsin\n \nVTDs\n\n \n\n\n\n\n\n \nwi_2020_vtd.csv\n\n\n\n\n\n\n\n \n\nWyoming\n \nVTDs\n\n \n\n\n\n\n\n \nwy_2020_vtd.csv"
  },
  {
    "objectID": "posts/2021-08-10-census-2020/census-2020.html#using-the-data",
    "href": "posts/2021-08-10-census-2020/census-2020.html#using-the-data",
    "title": "2020 Redistricting Data Files",
    "section": "Using the data",
    "text": "Using the data\n\nData Format\nEach data table contains several identification columns, a set of census-derived demographic columns, and a set of VEST-derived election columns.\n\nGEOID20 is the unique identifier for a precinct or Census block. The state and county of the precinct or block are also provided.\nCensus variables are prefixed with pop_ or vap_, depending on whether they are for the entire population or the voting-age population. Suffixes refer to racial and ethnic categories, as follows:\n\n_hisp: Hispanic or Latino (of any race)\n_white: White alone, not Hispanic or Latino\n_black: Black or African American alone, not Hispanic or Latino\n_aian: American Indian and Alaska Native alone, not Hispanic or Latino\n_asian: Asian alone, not Hispanic or Latino\n_nhpi: Native Hawaiian and Other Pacific Islander alone, not Hispanic or Latino\n_other: Some Other Race alone, not Hispanic or Latino\n_two: Population of two or more races, not Hispanic or Latino\n\nElection variables consist of average vote counts for Democratic and Republican candidates. The adv_## and arv_## columns report the average vote count in the ## election, across all statewide races contested by both parties. The ndv and nrv columns further average the vote counts across all available election years. For specific statewide races, you may download the files in vest-2020/ and join them to the data using the GEOID20 column.\n\n\n\nMore Tools\n\nFor redistricting and voting rights analysis, we recommend the redist package.\nFor pre-processing and tidying data for redistricting analysis, we recommend the geomander package.\nFor more custom tabulations of the 2020 census data, we recommend the PL94171 package.\nFor general-purpose census data processing, we recommend the censable package.\nFor alternate data unaffected by Census differential privacy, you may want to consider FCC block-level estimates, available using the blockpop package."
  },
  {
    "objectID": "posts/2021-08-10-census-2020/census-2020.html#technical-notes",
    "href": "posts/2021-08-10-census-2020/census-2020.html#technical-notes",
    "title": "2020 Redistricting Data Files",
    "section": "Technical notes",
    "text": "Technical notes\nTo produce election data using 2020 precinct boundaries, election results were projected down to the 2010 block level using voting-age population as weights. Results for 2020 blocks were then estimated using 2010 blocks and the land-use-based crosswalk files from VEST. Finally, 2020 blocks were aggregated to 2020 precincts using the Census’ 2020 block assignment files."
  },
  {
    "objectID": "posts/2021-08-10-census-2020/census-2020.html#data-addendum",
    "href": "posts/2021-08-10-census-2020/census-2020.html#data-addendum",
    "title": "2020 Redistricting Data Files",
    "section": "2010 Data Addendum",
    "text": "2010 Data Addendum\nIf you are looking for a similar construction for 2010 data, please see here."
  },
  {
    "objectID": "posts/2022-04-23-47-prefecture-project/47-prefecture-project.html",
    "href": "posts/2022-04-23-47-prefecture-project/47-prefecture-project.html",
    "title": "47-Prefecture Project",
    "section": "",
    "text": "The ALARM Project is pleased to announce the 47-Prefecture Project, whose goal is to generate and analyze redistricting plans for the single-member districts of the House of Representatives of Japan using redistricting simulation algorithms.\n\nLearn more about the project and see the results »"
  },
  {
    "objectID": "posts/2022-06-23-fifty-states-data-descriptor/fifty-states-data-descriptor.html",
    "href": "posts/2022-06-23-fifty-states-data-descriptor/fifty-states-data-descriptor.html",
    "title": "Fifty States Data Descriptor",
    "section": "",
    "text": "It’s been a long redistricting year. We’ve been tracking passed maps while conducting simulations in the 44 states with congressional districts. We are now finalizing some re-runs of states with new validation steps based on additional diagnostics, to ensure a high quality and accurate data product. So, we’ve written up a more detailed draft of what we did, how we did it, and how we checked our work. Most importantly, it introduces some tools so that you can use the data we’ve generated. It’s all open source and the redistricting plans generated are in the public domain.\nRead the detailed description of the our process and the data: Simulated redistricting plans for the analysis and evaluation of redistricting in the United States: 50stateSimulations. The abstract is listed below.\n\nThis article introduces the 50stateSimulations, a collection of simulated congressional districting plans and underlying code developed by the Algorithm-Assisted Redistricting Methodology (ALARM) Project. The 50stateSimulations allow for the evaluation of enacted and other congressional redistricting plans in the United States. While the use of redistricting simulation algorithms has become standard in academic research and court cases, any simulation analysis requires non-trivial efforts to combine multiple data sets, identify state-specific redistricting criteria, implement complex simulation algorithms, and summarize and visualize simulation outputs. We have developed a complete workflow that facilitates this entire process of simulation-based redistricting analysis for the congressional districts of all 50 states. The resulting 50stateSimulations include ensembles of simulated 2020 congressional redistricting plans and necessary replication data. We also provide the underlying code, which serves as a template for customized analyses. All data and code are free and publicly available. This article details the design, creation, and validation of the data.\n\nTo help make things more usable for those who don’t simulate redistricting plans in their free time, we are also excited to (soft) launch a new R package, alarmdata. This package provides a simplified interface to download the underlying geographic data, generated plans, all sorts of summary statistics, and state-by-state documentation.\nThe package can be installed with:\n\nremotes::install_github('alarm-redist/alarmdata')\n\nThank you to the Harvard Data Science Initiative and Microsoft for computational support."
  },
  {
    "objectID": "posts/2022-08-14-gerrymandering-mostly-cancels-nationally/gerrymandering-mostly-cancels-nationally.html",
    "href": "posts/2022-08-14-gerrymandering-mostly-cancels-nationally/gerrymandering-mostly-cancels-nationally.html",
    "title": "Widespread Partisan Gerrymandering Mostly Cancels Nationally, but Reduces Electoral Competition",
    "section": "",
    "text": "We’re excited to release a new working paper studying partisan bias in the 2020 US House plan. We employ redistricting simulations from the 50stateSimulations.1 with a model of partisanship to dig into geographic details of what happened where. Gerrymandering in 2020 redistricting makes the US House elections less competitive, but net seat gains are small nationally. The abstract below highlights more of our findings.\nAll in all, most of the states you thought were gerrymandered are indeed gerrymandered.\nSome gerrymandered states that you might have missed include those drawn by commissions (like Michigan and Iowa) and those drawn by courts (like Pennsylvania and North Carolina). The state-by-state results are below, with a national topline that the US map favors Republicans by about two seats beyond what’s explained by geography, on average.\nWe can take this further and look at a partisan manipulation map. Each district is colored by the difference in probability that it is represented by a Republican or Democrat in the enacted from the simulated plans. Red areas favor Republicans over simulations, blue areas favor Democrats over simulations. The darkness of each district represents the intensity of that difference.\nIf you’re interested in more information on our findings or methods, take a look here.\nA special thank you to George Garcia III, Kevin Wang, and Melissa Wu for their contributions to the 50stateSimulations which made this research possible."
  },
  {
    "objectID": "posts/2022-08-14-gerrymandering-mostly-cancels-nationally/gerrymandering-mostly-cancels-nationally.html#footnotes",
    "href": "posts/2022-08-14-gerrymandering-mostly-cancels-nationally/gerrymandering-mostly-cancels-nationally.html#footnotes",
    "title": "Widespread Partisan Gerrymandering Mostly Cancels Nationally, but Reduces Electoral Competition",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn case you missed it, we have a blog post introducing those simulations and their contributors.↩︎"
  },
  {
    "objectID": "posts/2022-10-13-policy-evaluation-commentary/policy-evaluation-commentary.html",
    "href": "posts/2022-10-13-policy-evaluation-commentary/policy-evaluation-commentary.html",
    "title": "Comment: The Essential Role of Policy Evaluation for the 2020 Census Disclosure Avoidance System",
    "section": "",
    "text": "We’re excited to announce a new paper, Comment: The Essential Role of Policy Evaluation for the 2020 Census Disclosure Avoidance System, now forthcoming at the Harvard Data Science Review. This article responds to boyd and Sarathy (2022). This builds on our research into the impact of differential privacy on redistricting and advances our responses to some common questions.\nThe abstract is listed below:\n\nIn “Differential Perspectives: Epistemic Disconnects Surrounding the US Census Bureau’s Use of Differential Privacy,” boyd and Sarathy argue that empirical evaluations of the Census Disclosure Avoidance System (DAS), including our published analysis, failed to recognize how the benchmark data against which the 2020 DAS was evaluated is never a ground truth of population counts. In this commentary, we explain why policy evaluation, which was the main goal of our analysis, is still meaningful without access to a perfect ground truth. We also point out that our evaluation leveraged features specific to the decennial Census and redistricting data, such as block-level population invariance under swapping and voter file racial identification, better approximating a comparison with the ground truth. Lastly, we show that accurate statistical predictions of individual race based on the Bayesian Improved Surname Geocoding, while not a violation of differential privacy, substantially increases the disclosure risk of private information the Census Bureau sought to protect. We conclude by arguing that policy makers must confront a key trade-off between data utility and privacy protection, and an epistemic disconnect alone is insufficient to explain disagreements between policy choices.\n\nFor those interested in the full commentary, a preprint is available here."
  },
  {
    "objectID": "posts/2022-12-15-statistical-software-award/statistical-software-award.html",
    "href": "posts/2022-12-15-statistical-software-award/statistical-software-award.html",
    "title": "redist Recieved POLMETH’s 2022 Statistical Software Award",
    "section": "",
    "text": "Last week, Chris Kenny, Cory McCartan, Ben Fifield, and Kosuke Imai received this year’s Statistical Software Award from the Society for Political Methodology for the R package redist.\nThe announcement stated:\n\nThe redist package by Christopher T Kenny, Cory McCartan, Ben Fifield, and Kosuke Imai of the Algorithm-Assisted Redistricting Methodology Project has rapidly become a key resource for researchers and practitioners seeking to evaluate redistricting plans. redist develops statistically grounded and computationally efficient procedures for generating random draws from a distribution of viable redistricting plans, including conditional distributions that satisfy specified requirements for geographic compactness and population parity. The package allows users to test for illegal partisan and racial gerrymandering, a timely and important question in the wake of the 2020 Census and the redistricting cycle that followed. It has had a substantial policy impact seeing use in legal challenges against and, unusually, has also been cited by six Supreme Court justices in oral arguments. In short, it is an ideal recipient of the Society for Political Methodolgy’s 2022 Statistical Software Award.\n\nWe are grateful for the honor! Thank you to the award committee for considering our software.\nredist is an open source R package for sampling redistricting plans, available here:\n\nThis R package enables researchers to sample redistricting plans from a pre-specified target distribution using Sequential Monte Carlo and Markov Chain Monte Carlo algorithms. The package supports various constraints in the redistricting process, such as geographic compactness and population parity requirements. Tools for analysis, including computation of various summary statistics and plotting functionality, are also included.\n\nredist is a key tool for much of our work, which has enabled work on identifying bias in Census 2020, creating alternative plans for all 50 states, reducing malapportionment in Japan, assessing partisan bias in 2022’s congressional districts, and more."
  },
  {
    "objectID": "posts/2023-03-18-redist-41/redist-41.html",
    "href": "posts/2023-03-18-redist-41/redist-41.html",
    "title": "redist 4.1",
    "section": "",
    "text": "It’s been a while since redist 4.0 was released and things have been fairly stable. Most of the changes in this release are behind-the-scenes improvements that shouldn’t break your workflow, but should improve your experience using the package.\nTo install version 4.1, get the new version from CRAN:\n\ninstall.packages('redist')\n\n\nNew Features\n\nExtends the ordered box/jitter plots to custom ordered geometries in redist.plot.distr_qtys()\nBetter diagnostic outputs for summary.redist_plans()\nImproved confidence intervals with redist_ci()\nC++ improvements for sampling more quickly\n\nBetter sampling efficiency in SMC’s final stage\nQuicker random walks for SMC and merge-split.\nFaster random number generation. (It’s small, but it adds up!)\n\n\n\n\nPlotting Flexibility with redist.plot.distr_qtys()\nBox-and-whiskers plots are great and useful in many situations. In redistricting, we’ve often used ordered boxplots. These order the x-axis by the quantity on the x-axis. Sometimes, a boxplot throws away information that you might care about, though. &gt;Is the distribution multi-modal? Where are the 2.5th and 97.5th percentiles for a confidence interval?\nNow, you can take those questions into your own hands with adjustments to arguments in redist.plot.distr_qtys()!\nLet’s build this out a bit. First, we’ll use some data from the 50-State Redistricting Simulations via the alarmdata package.\nWe can get the redist_map and corresponding 5,000 sampled plus the enacted plans in a redist_plans object for Michigan.\n\nlibrary(dplyr)\nlibrary(redist)\nlibrary(alarmdata)\nmap &lt;- alarm_50state_map('MI')\nplans &lt;- alarm_50state_plans('MI')\n\nplans here has a column e_dvs that gives the expected Democratic vote share for each district in each plan.\n\nredist.plot.distr_qtys(plans, qty = e_dvs)\n\n\n\n\n\n\n\n\nWe’ve always been able to clean or augment this plot up using regular ggplot2 things:\n\nlibrary(ggplot2)\n\nredist.plot.distr_qtys(plans, qty = e_dvs) + \n    geom_hline(yintercept = 0.5, linetype = 'dotted') + \n    scale_y_continuous(name = 'Expected Dem. Vote Share', labels = scales::label_percent(), \n                       limits = c(0.25, 0.95), breaks = seq(0.2, 0.9, by = 0.1)) +\n    theme_bw()\n\n\n\n\n\n\n\n\nYou can draw clear conclusions here, like that districts 2, 3, and 4 are abnormally packed with Republicans compared to what we might normally see when drawing districts that follow the state’s redistricting rules. We might not be able to get all of the information out of this plot that we want, beyond which districts are clear outliers.\nNow, if we made it a box plot instead of a jitter plot, as the points can be overwhelming, we can still draw the same major conclusions, and we now have a more formal idea of outliers that don’t just sit above or below the data. Things like district 6 can be still be a bit unclear. Is district 6 in the outlier range or are the points just big on this small plot?\n\nredist.plot.distr_qtys(plans, qty = e_dvs, geom = 'boxplot') + \n    geom_hline(yintercept = 0.5, linetype = 'dotted') + \n    scale_y_continuous(name = 'Expected Dem. Vote Share', labels = scales::label_percent(), \n                       limits = c(0.25, 0.95), breaks = seq(0.2, 0.9, by = 0.1)) +\n    theme_bw()\n\n\n\n\n\n\n\n\nA first thing we might consider doing is to use a violin plot instead of a boxplot, as that doesn’t summarize distributional information in the same way as a box plot. This is now really easy, just pass ggplot2::geom_violin as an argument to geom.\n\nredist.plot.distr_qtys(plans, qty = e_dvs, geom = ggplot2::geom_violin) + \n    geom_hline(yintercept = 0.5, linetype = 'dotted') + \n    scale_y_continuous(name = 'Expected Dem. Vote Share', labels = scales::label_percent(), \n                       limits = c(0.25, 0.95), breaks = seq(0.2, 0.9, by = 0.1)) +\n    theme_bw()\n\n\n\n\n\n\n\n\nThe defaults here don’t always play the best though, so we might want to also change the reference geometry.\n\nr_geom &lt;- function(...) \n    ggplot2::geom_segment(\n        ggplot2::aes(x = as.integer(.distr_no) - 0.5,\n                     xend = as.integer(.distr_no) + 0.5,\n                     yend = e_dvs,\n                     color = .data$draw),\n        ...\n    )\n\nThis immediately gets a bit more complicated. For this to work, we need to know a few things:\n\nThe function has to take ... as an argument.\nInternally, the variable we are plotting on the x is going to be called .distr_no.\nThe reference geometry will inherit x = .distr_no by default and y = qty, for whatever your input to qty is.\n\nThe above then says, on the x-axis, we want a line from the district - 0.5 to the district + 0.5, while we set yend = e_dvs to match the implicitly set y = e_dvs, since we passed qty = e_dvs before.\n\nredist.plot.distr_qtys(plans, qty = e_dvs, geom = ggplot2::geom_violin, ref_geom = r_geom) + \n    geom_hline(yintercept = 0.5, linetype = 'dotted') + \n    scale_y_continuous(name = 'Expected Dem. Vote Share', labels = scales::label_percent(), \n                       limits = c(0.25, 0.95), breaks = seq(0.2, 0.9, by = 0.1)) +\n    theme_bw()\n\n\n\n\n\n\n\n\nThe good thing here is that we can adjust the ref_geom however we see fit at this point. So if that red line is too dark, but also too skinny, we can do something like changing the alpha:\n\nr_geom &lt;- function(...) \n    ggplot2::geom_segment(\n        ggplot2::aes(x = as.integer(.distr_no) - 0.5,\n                     xend = as.integer(.distr_no) + 0.5,\n                     yend = e_dvs,\n                     color = .data$draw),\n        linewidth = 1, alpha = 0.7,\n        ...\n    )\n\nThen this fixes those particular issues.\n\nredist.plot.distr_qtys(plans, qty = e_dvs, geom = ggplot2::geom_violin, ref_geom = r_geom) + \n    geom_hline(yintercept = 0.5, linetype = 'dotted') + \n    scale_y_continuous(name = 'Expected Dem. Vote Share', labels = scales::label_percent(), \n                       limits = c(0.25, 0.95), breaks = seq(0.2, 0.9, by = 0.1)) +\n    theme_bw()\n\n\n\n\n\n\n\n\nNow, there are tons of other things we can do here. If we want to revisit the 95% confidence interval issue, we can turn to ggdist.\n\nlibrary(ggdist)\n\nredist.plot.distr_qtys(plans, qty = e_dvs, geom = stat_pointinterval, ref_geom = r_geom) + \n    geom_hline(yintercept = 0.5, linetype = 'dotted') + \n    scale_y_continuous(name = 'Expected Dem. Vote Share', labels = scales::label_percent(), \n                       limits = c(0.25, 0.95), breaks = seq(0.2, 0.9, by = 0.1)) +\n    theme_bw()\n\n\n\n\n\n\n\n\nNow, we have really clear idea of how wide the 95% confidence interval goes (via the length of the skinny lines).\nAnd really, the sky is the limit with packages like ggdist. For example, if we want a raincloud, we can do that.\n\nraincloud &lt;- function(...) {\n    list(\n        ggdist::stat_slab(aes(thickness = ggplot2::after_stat(pdf*n)), scale = 1),\n        ggdist::stat_dotsinterval(side = \"bottom\", scale = 1,\n                                  slab_size = NA, quantiles = 100)\n    )\n}\n\nThis gives us a fun plot to work with, though this might be best suited for much larger plot areas.\n\nredist.plot.distr_qtys(plans, qty = e_dvs, geom = raincloud, ref_geom = r_geom) + \n    geom_hline(yintercept = 0.5, linetype = 'dotted') + \n    scale_y_continuous(name = 'Expected Dem. Vote Share', labels = scales::label_percent(), \n                       limits = c(0.35, 0.95), breaks = seq(0.2, 0.9, by = 0.1)) +\n    theme_bw()\n\n\n\n\n\n\n\n\n\n\nBetter Diagnostics for summary.redist_plans()\nLike above, let’s get some simulated plans from the 50-State Redistricting Simulations. We can get a state like Nevada, which has fewer districts and shorter summary.\n\nlibrary(alarmdata)\nplans &lt;- alarm_50state_plans('NV')\n\nTo get diagnostics, we can call summary(plans) which computes R-hats, sample diversity, and some split-by-split SMC diagnostics.\n\nsummary(plans)\n\nSMC: 5,000 sampled plans of 4 districts on 2,102 units\n\n\n`adapt_k_thresh`=0.985 • `seq_alpha`=0.5\n\n\n`pop_temper`=0\n\n\nPlan diversity 80% range: 0.55 to 0.75\n\n\n\nR-hat values for summary statistics:\n   pop_overlap      total_vap       plan_dev      comp_edge    comp_polsby \n         1.003          1.003          1.001          1.000          1.000 \n      pop_hisp      pop_white      pop_black       pop_aian      pop_asian \n         1.009          1.005          1.003          1.002          1.003 \n      pop_nhpi      pop_other        pop_two       vap_hisp      vap_white \n         1.000          1.003          1.003          1.007          1.006 \n     vap_black       vap_aian      vap_asian       vap_nhpi      vap_other \n         1.004          1.001          1.002          1.000          1.007 \n       vap_two pre_16_dem_cli pre_16_rep_tru uss_16_dem_cor uss_16_rep_hec \n         1.003          1.001          1.003          1.000          1.004 \nuss_18_dem_ros uss_18_rep_hel gov_18_dem_sis gov_18_rep_lax atg_18_dem_for \n         1.002          1.002          1.002          1.003          1.001 \natg_18_rep_dun sos_18_dem_ara sos_18_rep_ceg pre_20_dem_bid pre_20_rep_tru \n         1.002          1.001          1.003          1.002          1.004 \n        arv_16         adv_16         arv_18         adv_18         arv_20 \n         1.003          1.000          1.003          1.002          1.004 \n        adv_20  county_splits    muni_splits            ndv            nrv \n         1.002          1.002          1.003          1.002          1.003 \n       ndshare          e_dvs         pr_dem          e_dem          pbias \n         1.003          1.003          1.001          1.002          1.000 \n          egap \n         1.001 \n\n\nSampling diagnostics for SMC run 1 of 2 (2,500 samples)\n\n\n         Eff. samples (%) Acc. rate Log wgt. sd  Max. unique Est. k \nSplit 1     2,215 (88.6%)     19.7%        0.93 1,583 (100%)     10 \nSplit 2     2,287 (91.5%)     12.8%        0.51 1,565 ( 99%)      6 \nSplit 3     2,242 (89.7%)      5.9%        0.56 1,441 ( 91%)      4 \nResample    1,352 (54.1%)       NA%        0.57 1,409 ( 89%)     NA \n\n\nSampling diagnostics for SMC run 2 of 2 (2,500 samples)\n\n\n         Eff. samples (%) Acc. rate Log wgt. sd  Max. unique Est. k \nSplit 1     2,228 (89.1%)     15.1%        0.91 1,584 (100%)     13 \nSplit 2     2,285 (91.4%)      9.7%        0.52 1,574 (100%)      8 \nSplit 3     2,236 (89.4%)      5.0%        0.58 1,444 ( 91%)      5 \nResample    1,471 (58.8%)       NA%        0.59 1,399 ( 89%)     NA \n\n\n• Watch out for low effective samples, very low acceptance rates (less than\n1%), large std. devs. of the log weights (more than 3 or so), and low numbers\nof unique plans. R-hat values for summary statistics should be between 1 and\n1.05.\n\n\nThe first big change here is that the digits are now rounded to three digits. You no longer need to search through 8 decimal digits at 3am for the ones that matter.\nTypically, we want R-hat values between 1 and 1.05, so this looks pretty good. What if they weren’t? We can introduce this behavior by adding some new variable with very different values by independent run of SMC (denoted by the chain column).\n\nplans &lt;- plans %&gt;% \n    mutate(bad_rhat = rnorm(n = n(), mean = dplyr::coalesce(chain, 0)))\n\nNow this gets angry:\n\nsummary(plans)\n\nSMC: 5,000 sampled plans of 4 districts on 2,102 units\n\n\n`adapt_k_thresh`=0.985 • `seq_alpha`=0.5\n\n\n`pop_temper`=0\n\n\nPlan diversity 80% range: 0.54 to 0.73\n\n\n\nR-hat values for summary statistics:\n   pop_overlap      total_vap       plan_dev      comp_edge    comp_polsby \n         1.003          1.003          1.001          1.000          1.000 \n      pop_hisp      pop_white      pop_black       pop_aian      pop_asian \n         1.009          1.005          1.003          1.002          1.003 \n      pop_nhpi      pop_other        pop_two       vap_hisp      vap_white \n         1.000          1.003          1.003          1.007          1.006 \n     vap_black       vap_aian      vap_asian       vap_nhpi      vap_other \n         1.004          1.001          1.002          1.000          1.007 \n       vap_two pre_16_dem_cli pre_16_rep_tru uss_16_dem_cor uss_16_rep_hec \n         1.003          1.001          1.003          1.000          1.004 \nuss_18_dem_ros uss_18_rep_hel gov_18_dem_sis gov_18_rep_lax atg_18_dem_for \n         1.002          1.002          1.002          1.003          1.001 \natg_18_rep_dun sos_18_dem_ara sos_18_rep_ceg pre_20_dem_bid pre_20_rep_tru \n         1.002          1.001          1.003          1.002          1.004 \n        arv_16         adv_16         arv_18         adv_18         arv_20 \n         1.003          1.000          1.003          1.002          1.004 \n        adv_20  county_splits    muni_splits            ndv            nrv \n         1.002          1.002          1.003          1.002          1.003 \n       ndshare          e_dvs         pr_dem          e_dem          pbias \n         1.003          1.003          1.001          1.002          1.000 \n          egap       bad_rhat \n         1.001        ❌1.245 \n\n\n✖ WARNING: SMC runs have not converged.\n\n\nSampling diagnostics for SMC run 1 of 2 (2,500 samples)\n\n\n         Eff. samples (%) Acc. rate Log wgt. sd  Max. unique Est. k \nSplit 1     2,215 (88.6%)     19.7%        0.93 1,583 (100%)     10 \nSplit 2     2,287 (91.5%)     12.8%        0.51 1,565 ( 99%)      6 \nSplit 3     2,242 (89.7%)      5.9%        0.56 1,441 ( 91%)      4 \nResample    1,352 (54.1%)       NA%        0.57 1,409 ( 89%)     NA \n\n\nSampling diagnostics for SMC run 2 of 2 (2,500 samples)\n\n\n         Eff. samples (%) Acc. rate Log wgt. sd  Max. unique Est. k \nSplit 1     2,228 (89.1%)     15.1%        0.91 1,584 (100%)     13 \nSplit 2     2,285 (91.4%)      9.7%        0.52 1,574 (100%)      8 \nSplit 3     2,236 (89.4%)      5.0%        0.58 1,444 ( 91%)      5 \nResample    1,471 (58.8%)       NA%        0.59 1,399 ( 89%)     NA \n\n\n• Watch out for low effective samples, very low acceptance rates (less than\n1%), large std. devs. of the log weights (more than 3 or so), and low numbers\nof unique plans. R-hat values for summary statistics should be between 1 and\n1.05.\n\n\n• SMC convergence: Increase the number of samples. If you are experiencing low\nplan diversity or bottlenecks as well, address those issues first.\n\n\nIt warns about convergence, as it has since 4.0. But it now also adds a big red “x” next to bad_rhat’s R-hat.\n\nAny questions? Open an issue on GitHub or find us on Twitter."
  },
  {
    "objectID": "posts/2023-06-03-census-letter/census-letter.html",
    "href": "posts/2023-06-03-census-letter/census-letter.html",
    "title": "Letter: Researchers need better access to US Census data published in Science",
    "section": "",
    "text": "For the 2020 decennial census, the Census Bureau adopted a new Disclosure Avoidance System (DAS) based on differential privacy. The DAS was designed to protect the confidentiality of responses by injecting statistical noise into a confidential individual census dataset. A key output of this system is the Noisy Measurement File (NMF), which is produced by adding random noise to tabulated statistics. The resulting Noisy Measurement File (NMF) is an invaluable resource for Census data users to understand the error introduced by the DAS and perform statistically valid analyses that properly account for DAS-introduced error.\nThe Bureau did not initially release the NMF, but released a demonstration version in April 2023 after several public requests and subsequent litigation. The Bureau plans to release the NMF for the P.L.94-171 redistricting data and more detailed census data (the DHC file) later this year.\nWe commend the Bureau’s decision to provide the NMF, which will help advance social science research, improve policy decisions, and further strengthen the DAS itself. To maximize the benefits of the released NMF, however, we believe that the Bureau must substantially improve the way in which the NMF is formatted and released. In a letter recently published in Science, we explain several obstacles researchers may face when accessing, processing, and using the demonstration data for statistical analyses. We include several recommendations for the Bureau for future NMF releases. Our longer version of this letter describes how researchers can transform the NMF into a usable format and includes more detailed recommendations."
  },
  {
    "objectID": "posts/2023-06-14-census-bias-and-noise-wp/census-bias-and-noise-wp.html",
    "href": "posts/2023-06-14-census-bias-and-noise-wp/census-bias-and-noise-wp.html",
    "title": "Working Paper: Evaluating Bias and Noise Induced by the U.S. Census Bureau’s Privacy Protection Methods",
    "section": "",
    "text": "We are excited to announce a new working paper Evaluating Bias and Noise Induced by the U.S. Census Bureau’s Privacy Protection Methods. This paper is the first independent evaluation of effects of the Census Bureau’s privacy protection on noise and bias in released counts. We leverage the recent release of the Noisy Measurements file (NMF) to evaluate both swapping and the newer TopDown algorithm.\nWe find that:\n\nthe NMF is too noisy to use alone, but the post-processing step of the TopDown algorithm reduces error substantially, making the post-processed data as accurate as swapping.\nerrors from privacy protection methods are generally smaller than other sources of census errors, they can be substantial for census geographies with small populations.\nthe average bias is fairly low across groups, but there is more uncertainty and noise for Hispanic and multiracial people. Bias and RMSE estimates nationally for 5 geographic levels are displayed by race group below.\n\n\n\n\n\n\n\n\n\n\nThe full abstract is below:\n\nThe United States Census Bureau faces a difficult trade-off between the accuracy of Census statistics and the protection of individual information. We conduct the first independent evaluation of bias and noise induced by the Bureau’s two main disclosure avoidance systems: the TopDown algorithm employed for the 2020 nsus and the swapping algorithm implemented for the 1990, 2000, and 2010 Censuses. Our evaluation leverages the recent release of the Noisy Measure File (NMF) as well as the availability of two independent runs of the TopDown algorithm applied to the 10 decennial Census. We find that the NMF contains too much noise to be directly useful alone, especially for Hispanic and multiracial populations. TopDown’s post-processing dramatically reduces the NMF noise and produces similarly accurate data to swapping in terms of bias and noise. These patterns hold across census geographies with varying population sizes and racial diversity. While the estimated errors for both TopDown and swapping are generally no larger than other sources of Census error, they can be relatively substantial for geographies with small total populations."
  }
]